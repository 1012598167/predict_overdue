{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T10:28:29.013773Z",
     "start_time": "2019-12-15T10:28:29.009791Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"#让所有不是在最后一行的单个变量也能print\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林与Adaboost与XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandasprofilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:16.071795Z",
     "start_time": "2019-12-15T13:23:16.007004Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merge_loan = pd.read_csv(\"merge_loan_test.csv\")\n",
    "merge_loan_train = pd.read_csv(\"merge_loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T17:54:24.752057Z",
     "start_time": "2019-11-22T17:53:38.932494Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas_profiling\n",
    "\n",
    "#To display the report in a Jupyter notebook, run:\n",
    "\n",
    "merge_loan.profile_report(style={'full_width':True})\n",
    "#To retrieve the list of variables which are rejected due to high correlation:\n",
    "\n",
    "#profile = df.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T20:52:37.359723Z",
     "start_time": "2019-11-17T20:52:37.355704Z"
    }
   },
   "source": [
    "## 热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:00:42.596897Z",
     "start_time": "2019-11-17T21:00:42.591937Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_group1=merge_loan[['I_1', 'I_2', 'I_3', 'P_1', 'P_2', 'P_3','log_sum_send_amount','lend_period','view_no','30days_overdue_times','is_30days_overdue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:00:44.686092Z",
     "start_time": "2019-11-17T21:00:44.116537Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(feature_group1.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:01:05.032197Z",
     "start_time": "2019-11-17T21:01:05.026192Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_group2=merge_loan[['sum_his_lend_amount', 'mean_his_overdue_times', 'sum_before_30_trans_amount', 'mean_every_day_trans_amount', 'cv_mean_every_day_trans_amount', 'sum_every_trans_amount','on_sale_rate','sum_before_30_trans_count','sum_every_trans_count','nearest_trans_day','mean_every_trans_trans_amount','is_30days_overdue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:01:08.121045Z",
     "start_time": "2019-11-17T21:01:07.349054Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_group2.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以看到按相关性相对高的特征结合 特征间相关系数都特别低 说明特征离散得不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:01:21.297687Z",
     "start_time": "2019-11-17T21:01:21.293697Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_group3=merge_loan[['bankcard_credit_count','bankcard_debit_count','wallet_weixin_count','wallet_alipay_count','alipay_huabei_count','is_30days_overdue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:01:22.842359Z",
     "start_time": "2019-11-17T21:01:22.567584Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_group3.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:01:37.013355Z",
     "start_time": "2019-11-17T21:01:37.006874Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_group4=merge_loan[['mean_good_status','store_num','terminal_num','on_sale_or_not','mean_payer_uid','is_30days_overdue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:01:38.467177Z",
     "start_time": "2019-11-17T21:01:38.184418Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_group4.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:05:12.265167Z",
     "start_time": "2019-11-17T21:05:12.258165Z"
    }
   },
   "outputs": [],
   "source": [
    "del merge_loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层次聚类图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T20:55:09.747207Z",
     "start_time": "2019-11-17T20:55:09.240495Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(feature_group4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要的库\n",
    "### 这边暂时先不卡方分箱，离群检测等，现测试一波看下准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T15:54:47.472870Z",
     "start_time": "2019-11-25T15:54:47.248822Z"
    }
   },
   "outputs": [],
   "source": [
    "# k 折交叉验证（k-fold cross validation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:11:53.381672Z",
     "start_time": "2019-11-17T21:11:53.137750Z"
    }
   },
   "source": [
    "## 选择需要的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:26.385167Z",
     "start_time": "2019-12-15T13:23:26.379195Z"
    }
   },
   "outputs": [],
   "source": [
    "feature=merge_loan[['I_1', 'I_2', 'I_3', 'P_1', 'P_2', 'P_3','log_sum_send_amount','lend_period','view_no',\\\n",
    "                    'sum_his_lend_amount', 'mean_his_overdue_times', 'sum_before_30_trans_amount', 'mean_every_day_trans_amount', 'cv_mean_every_day_trans_amount', 'sum_every_trans_amount','on_sale_rate','sum_before_30_trans_count','sum_every_trans_count','nearest_trans_day','mean_every_trans_trans_amount',\\\n",
    "                    'mean_good_status','store_num','terminal_num','on_sale_or_not','mean_payer_uid',\\\n",
    "                    'bankcard_credit_count','bankcard_debit_count','wallet_weixin_count','wallet_alipay_count','alipay_huabei_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:27.529638Z",
     "start_time": "2019-12-15T13:23:27.523654Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_train=merge_loan_train[['I_1', 'I_2', 'I_3', 'P_1', 'P_2', 'P_3','log_sum_send_amount','lend_period','view_no',\\\n",
    "                    'sum_his_lend_amount', 'mean_his_overdue_times', 'sum_before_30_trans_amount', 'mean_every_day_trans_amount', 'cv_mean_every_day_trans_amount', 'sum_every_trans_amount','on_sale_rate','sum_before_30_trans_count','sum_every_trans_count','nearest_trans_day','mean_every_trans_trans_amount',\\\n",
    "                    'mean_good_status','store_num','terminal_num','on_sale_or_not','mean_payer_uid',\\\n",
    "                    'bankcard_credit_count','bankcard_debit_count','wallet_weixin_count','wallet_alipay_count','alipay_huabei_count','is_30days_overdue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:28.956851Z",
     "start_time": "2019-12-15T13:23:28.826201Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature['cv_mean_every_day_trans_amount']=feature['cv_mean_every_day_trans_amount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:29.043630Z",
     "start_time": "2019-12-15T13:23:29.012702Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_train['cv_mean_every_day_trans_amount']=feature_train['cv_mean_every_day_trans_amount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:29.409641Z",
     "start_time": "2019-12-15T13:23:29.402658Z"
    }
   },
   "outputs": [],
   "source": [
    "feature=feature.drop(['bankcard_credit_count','bankcard_debit_count','wallet_weixin_count','wallet_alipay_count','alipay_huabei_count'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:29.418624Z",
     "start_time": "2019-12-15T13:23:29.411642Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_train=feature_train.drop(['bankcard_credit_count','bankcard_debit_count','wallet_weixin_count','wallet_alipay_count','alipay_huabei_count'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:31.807740Z",
     "start_time": "2019-12-15T13:23:31.802753Z"
    }
   },
   "outputs": [],
   "source": [
    "feature=feature.drop(['I_1', 'I_2', 'I_3', 'P_1', 'P_2', 'P_3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:32.090573Z",
     "start_time": "2019-12-15T13:23:32.086480Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_train=feature_train.drop(['I_1', 'I_2', 'I_3', 'P_1', 'P_2', 'P_3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:23:36.275994Z",
     "start_time": "2019-12-15T13:23:36.269011Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature['sum_his_lend_amount']=feature['sum_his_lend_amount'].map(lambda i:np.log(i) if i>0 else 0)\n",
    "feature_train['sum_his_lend_amount']=feature_train['sum_his_lend_amount'].map(lambda i:np.log(i) if i>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:27:31.851424Z",
     "start_time": "2019-12-15T13:27:31.846436Z"
    }
   },
   "outputs": [],
   "source": [
    "feature['log_sum_send_amount']=feature['log_sum_send_amount'].map(lambda i:np.exp(i) if i>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:51:14.878844Z",
     "start_time": "2019-12-15T13:51:14.840942Z"
    }
   },
   "outputs": [],
   "source": [
    "feature=feature.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "feature_train=feature_train.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T15:58:56.265500Z",
     "start_time": "2019-11-25T15:58:56.258463Z"
    }
   },
   "outputs": [],
   "source": [
    "feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T15:59:02.820014Z",
     "start_time": "2019-11-25T15:59:02.813946Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:51:17.211590Z",
     "start_time": "2019-12-15T13:51:17.181642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_sum_send_amount</th>\n",
       "      <th>lend_period</th>\n",
       "      <th>view_no</th>\n",
       "      <th>sum_his_lend_amount</th>\n",
       "      <th>mean_his_overdue_times</th>\n",
       "      <th>sum_before_30_trans_amount</th>\n",
       "      <th>mean_every_day_trans_amount</th>\n",
       "      <th>cv_mean_every_day_trans_amount</th>\n",
       "      <th>sum_every_trans_amount</th>\n",
       "      <th>on_sale_rate</th>\n",
       "      <th>sum_before_30_trans_count</th>\n",
       "      <th>sum_every_trans_count</th>\n",
       "      <th>nearest_trans_day</th>\n",
       "      <th>mean_every_trans_trans_amount</th>\n",
       "      <th>mean_good_status</th>\n",
       "      <th>store_num</th>\n",
       "      <th>terminal_num</th>\n",
       "      <th>on_sale_or_not</th>\n",
       "      <th>mean_payer_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283476</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.708267</td>\n",
       "      <td>0.681788</td>\n",
       "      <td>0.116594</td>\n",
       "      <td>0.762552</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561611</td>\n",
       "      <td>0.935056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.473908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.757589</td>\n",
       "      <td>0.712411</td>\n",
       "      <td>0.372269</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.996128</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744346</td>\n",
       "      <td>0.818146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116402</td>\n",
       "      <td>0.088984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.348594</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.548158</td>\n",
       "      <td>0.764678</td>\n",
       "      <td>0.320512</td>\n",
       "      <td>0.711933</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.794644</td>\n",
       "      <td>0.449864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.361470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141738</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.838826</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.332435</td>\n",
       "      <td>0.856913</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784040</td>\n",
       "      <td>0.932021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.821560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.677505</td>\n",
       "      <td>0.731782</td>\n",
       "      <td>0.172372</td>\n",
       "      <td>0.738287</td>\n",
       "      <td>0.991337</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.565122</td>\n",
       "      <td>0.904829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156962</td>\n",
       "      <td>0.481249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.691458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685003</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.737560</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>0.271281</td>\n",
       "      <td>0.772912</td>\n",
       "      <td>0.969885</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610681</td>\n",
       "      <td>0.891572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.114014</td>\n",
       "      <td>0.420009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.488854</td>\n",
       "      <td>0.594147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.595828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.770418</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.612580</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844267</td>\n",
       "      <td>0.792070</td>\n",
       "      <td>0.137174</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>0.986872</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585341</td>\n",
       "      <td>0.984555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172561</td>\n",
       "      <td>0.446453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.207351</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.756071</td>\n",
       "      <td>0.791299</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>0.792487</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.902783</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.480303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.805717</td>\n",
       "      <td>0.845970</td>\n",
       "      <td>0.267214</td>\n",
       "      <td>0.818018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.967967</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.585275</td>\n",
       "      <td>0.590105</td>\n",
       "      <td>0.250805</td>\n",
       "      <td>0.903136</td>\n",
       "      <td>0.876694</td>\n",
       "      <td>0.193427</td>\n",
       "      <td>0.918974</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767887</td>\n",
       "      <td>0.904527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.685529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617630</td>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900688</td>\n",
       "      <td>0.870635</td>\n",
       "      <td>0.215829</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>0.986701</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571007</td>\n",
       "      <td>0.968058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.325189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.533822</td>\n",
       "      <td>0.535109</td>\n",
       "      <td>0.267675</td>\n",
       "      <td>0.583387</td>\n",
       "      <td>0.996558</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.622408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.800873</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.439033</td>\n",
       "      <td>0.815644</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.893092</td>\n",
       "      <td>0.484444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.248172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.791434</td>\n",
       "      <td>0.756473</td>\n",
       "      <td>0.182442</td>\n",
       "      <td>0.818474</td>\n",
       "      <td>0.990046</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750219</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.745378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.690290</td>\n",
       "      <td>0.656154</td>\n",
       "      <td>0.864225</td>\n",
       "      <td>0.703082</td>\n",
       "      <td>0.956956</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.694967</td>\n",
       "      <td>0.826412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.562654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.397908</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.784968</td>\n",
       "      <td>0.747255</td>\n",
       "      <td>0.414548</td>\n",
       "      <td>0.806658</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688212</td>\n",
       "      <td>0.893543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134513</td>\n",
       "      <td>0.764757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.573243</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.852850</td>\n",
       "      <td>0.832371</td>\n",
       "      <td>0.320242</td>\n",
       "      <td>0.869076</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.651275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.398468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.511115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681384</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.524831</td>\n",
       "      <td>0.596954</td>\n",
       "      <td>0.251150</td>\n",
       "      <td>0.764726</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882345</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.190521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.641160</td>\n",
       "      <td>0.607528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.750427</td>\n",
       "      <td>0.055506</td>\n",
       "      <td>0.818207</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566994</td>\n",
       "      <td>0.943104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.128899</td>\n",
       "      <td>0.573588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    log_sum_send_amount  lend_period   view_no  sum_his_lend_amount  \\\n",
       "0              0.207351     1.000000  0.283476             0.585836   \n",
       "1              0.434588     0.454545  0.082911             0.567290   \n",
       "2              0.303764     0.181818  0.348594             0.567290   \n",
       "3              0.738352     1.000000  0.141738             0.585836   \n",
       "4              0.303764     0.181818  0.082911             0.602248   \n",
       "5              0.691458     1.000000  0.685003             0.567290   \n",
       "6              0.303764     0.727273  0.490332             0.585836   \n",
       "7              0.738352     0.272727  0.612580             0.738352   \n",
       "8              0.434588     1.000000  0.307560             0.207351   \n",
       "9              0.303764     0.454545  0.412016             0.392472   \n",
       "10             0.738352     0.272727  0.585275             0.590105   \n",
       "11             0.738352     1.000000  0.617630             0.641939   \n",
       "12             0.303764     0.454545  0.673947             0.602248   \n",
       "13             0.565412     0.454545  0.425213             0.567290   \n",
       "14             0.738352     0.000000  0.412016             0.567290   \n",
       "15             0.392472     0.181818  0.412016             0.602248   \n",
       "16             0.511115     0.727273  0.397908             0.452577   \n",
       "17             0.738352     0.363636  0.573243             0.567290   \n",
       "18             0.511115     1.000000  0.681384             0.567290   \n",
       "19             0.434588     0.181818  0.641160             0.607528   \n",
       "\n",
       "    mean_his_overdue_times  sum_before_30_trans_amount  \\\n",
       "0                 0.342857                    0.708267   \n",
       "1                 0.388000                    0.757589   \n",
       "2                 0.388000                    0.548158   \n",
       "3                 0.342857                    0.838826   \n",
       "4                 0.229310                    0.677505   \n",
       "5                 0.388000                    0.737560   \n",
       "6                 0.342857                    0.488854   \n",
       "7                 0.000000                    0.844267   \n",
       "8                 0.200000                    0.756071   \n",
       "9                 0.800000                    0.805717   \n",
       "10                0.250805                    0.903136   \n",
       "11                0.000000                    0.900688   \n",
       "12                0.229310                    0.533822   \n",
       "13                0.388000                    0.800873   \n",
       "14                0.388000                    0.791434   \n",
       "15                0.229310                    0.690290   \n",
       "16                0.200000                    0.784968   \n",
       "17                0.388000                    0.852850   \n",
       "18                0.388000                    0.524831   \n",
       "19                0.000000                    0.800412   \n",
       "\n",
       "    mean_every_day_trans_amount  cv_mean_every_day_trans_amount  \\\n",
       "0                      0.681788                        0.116594   \n",
       "1                      0.712411                        0.372269   \n",
       "2                      0.764678                        0.320512   \n",
       "3                      0.805407                        0.332435   \n",
       "4                      0.731782                        0.172372   \n",
       "5                      0.694447                        0.271281   \n",
       "6                      0.594147                        0.000000   \n",
       "7                      0.792070                        0.137174   \n",
       "8                      0.791299                        0.201353   \n",
       "9                      0.845970                        0.267214   \n",
       "10                     0.876694                        0.193427   \n",
       "11                     0.870635                        0.215829   \n",
       "12                     0.535109                        0.267675   \n",
       "13                     0.867200                        0.439033   \n",
       "14                     0.756473                        0.182442   \n",
       "15                     0.656154                        0.864225   \n",
       "16                     0.747255                        0.414548   \n",
       "17                     0.832371                        0.320242   \n",
       "18                     0.596954                        0.251150   \n",
       "19                     0.750427                        0.055506   \n",
       "\n",
       "    sum_every_trans_amount  on_sale_rate  sum_before_30_trans_count  \\\n",
       "0                 0.762552      0.989301                   0.189189   \n",
       "1                 0.784500      0.996128                   0.310811   \n",
       "2                 0.711933      0.997082                   0.040541   \n",
       "3                 0.856913      0.998964                   0.797297   \n",
       "4                 0.738287      0.991337                   0.040541   \n",
       "5                 0.772912      0.969885                   0.891892   \n",
       "6                 0.595828      1.000000                   0.000000   \n",
       "7                 0.855037      0.986872                   0.689189   \n",
       "8                 0.792487      0.999581                   0.135135   \n",
       "9                 0.818018      1.000000                   0.108108   \n",
       "10                0.918974      0.999134                   0.864865   \n",
       "11                0.910283      0.986701                   0.405405   \n",
       "12                0.583387      0.996558                   0.243243   \n",
       "13                0.815644      0.999995                   0.148649   \n",
       "14                0.818474      0.990046                   0.513514   \n",
       "15                0.703082      0.956956                   0.229730   \n",
       "16                0.806658      0.996205                   0.459459   \n",
       "17                0.869076      0.990873                   0.554054   \n",
       "18                0.764726      0.999136                   0.040541   \n",
       "19                0.818207      0.986894                   0.405405   \n",
       "\n",
       "    sum_every_trans_count  nearest_trans_day  mean_every_trans_trans_amount  \\\n",
       "0                0.626667           0.000000                       0.561611   \n",
       "1                0.773333           0.000000                       0.744346   \n",
       "2                0.160000           0.000000                       0.794644   \n",
       "3                0.973333           0.000000                       0.784040   \n",
       "4                0.226667           0.144928                       0.565122   \n",
       "5                1.000000           0.000000                       0.610681   \n",
       "6                0.026667           0.115942                       0.770418   \n",
       "7                1.000000           0.000000                       0.585341   \n",
       "8                0.226667           0.014493                       0.902783   \n",
       "9                0.133333           0.202899                       0.967967   \n",
       "10               0.986667           0.000000                       0.767887   \n",
       "11               1.000000           0.000000                       0.571007   \n",
       "12               0.293333           0.246377                       0.582906   \n",
       "13               0.146667           0.057971                       0.893092   \n",
       "14               0.893333           0.000000                       0.750219   \n",
       "15               0.293333           0.028986                       0.694967   \n",
       "16               0.946667           0.000000                       0.688212   \n",
       "17               0.706667           0.000000                       0.896178   \n",
       "18               0.146667           0.000000                       0.882345   \n",
       "19               1.000000           0.000000                       0.566994   \n",
       "\n",
       "    mean_good_status  store_num  terminal_num  on_sale_or_not  mean_payer_uid  \n",
       "0           0.935056   0.000000      0.024390        0.105426        0.473908  \n",
       "1           0.818146   0.000000      0.000000        0.116402        0.088984  \n",
       "2           0.449864   0.000000      0.024390        0.146341        0.361470  \n",
       "3           0.932021   0.000000      0.024390        0.126582        0.821560  \n",
       "4           0.904829   0.000000      0.000000        0.156962        0.481249  \n",
       "5           0.891572   0.000000      0.024390        0.114014        0.420009  \n",
       "6           0.328704   0.000000      0.048780        0.000000        0.496544  \n",
       "7           0.984555   0.000000      0.000000        0.172561        0.446453  \n",
       "8           0.688172   0.000000      0.000000        0.064516        0.480303  \n",
       "9           0.309524   0.000000      0.000000        0.000000        0.208855  \n",
       "10          0.904527   0.000000      0.146341        0.105706        0.685529  \n",
       "11          0.968058   0.000000      0.170732        0.081866        0.325189  \n",
       "12          0.899306   0.058824      0.024390        0.125000        0.622408  \n",
       "13          0.484444   0.000000      0.000000        0.026667        0.248172  \n",
       "14          0.783951   0.117647      0.073171        0.051724        0.745378  \n",
       "15          0.826412   0.000000      0.024390        0.040404        0.562654  \n",
       "16          0.893543   0.000000      0.000000        0.134513        0.764757  \n",
       "17          0.651275   0.000000      0.073171        0.116883        0.398468  \n",
       "18          0.283951   0.000000      0.024390        0.039216        0.190521  \n",
       "19          0.943104   0.000000      0.048780        0.128899        0.573588  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:14:29.865235Z",
     "start_time": "2019-12-15T13:14:29.857255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362    0.0\n",
       "Name: mean_every_day_trans_amount, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature['mean_every_day_trans_amount'][feature['mean_every_day_trans_amount']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:14:31.523004Z",
     "start_time": "2019-12-15T13:14:31.516018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54      0.0\n",
       "235     0.0\n",
       "355     0.0\n",
       "555     0.0\n",
       "1016    0.0\n",
       "Name: mean_every_day_trans_amount, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train['mean_every_day_trans_amount'][feature_train['mean_every_day_trans_amount']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到日均交易额变异系数明显有缺失值 分析是除以均值时均值为0所致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最终结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T14:09:46.905686Z",
     "start_time": "2019-12-15T14:09:46.860787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=7, max_features=15, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "train_data = feature_train.drop(['is_30days_overdue'], axis=1)\n",
    "train_target = feature_train['is_30days_overdue']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.25, random_state=1)\n",
    "# clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "#             max_depth=7, max_features=15, max_leaf_nodes=None,\n",
    "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#             min_samples_leaf=2, min_samples_split=4,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n",
    "#             oob_score=False, random_state=None, verbose=0,\n",
    "#             warm_start=False)\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "# clf = joblib.load('RFC.m')\n",
    "# # clf = clf.fit(train_data,train_target)\n",
    "# print(clf)\n",
    "# y_RF = clf.predict(feature)\n",
    "# clf = joblib.load('RFC2.m')\n",
    "# y_RF2 = clf.predict(feature)\n",
    "\n",
    "\n",
    "# f1_score(y_test,y_pridict)\n",
    "clf = joblib.load('RF_gcy_872209.m')\n",
    "clf\n",
    "y_RF2 = clf.predict(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T14:09:50.639809Z",
     "start_time": "2019-12-15T14:09:50.630803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_RF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T14:09:52.660054Z",
     "start_time": "2019-12-15T14:09:52.642940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(y_RF2).count('0')\n",
    "str(y_RF2).count('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T14:10:03.758926Z",
     "start_time": "2019-12-15T14:10:03.753939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_RF2 = pd.DataFrame()\n",
    "print(df_RF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T14:10:05.002702Z",
     "start_time": "2019-12-15T14:10:04.996718Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_RF2.insert(0, 'y_predict', y_RF2)\n",
    "df_RF2.insert(0, 'apply_id', merge_loan['apply_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T14:10:05.601128Z",
     "start_time": "2019-12-15T14:10:05.592123Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apply_id</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50557025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49510913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50782824</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51967846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51105993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apply_id  y_predict\n",
       "0  50557025        1.0\n",
       "1  49510913        0.0\n",
       "2  50782824        1.0\n",
       "3  51967846        0.0\n",
       "4  51105993        1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T14:10:31.567776Z",
     "start_time": "2019-12-15T14:10:31.560767Z"
    }
   },
   "outputs": [],
   "source": [
    "df_RF2.to_csv('RFpredict_changef1_11252210.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:00:38.385372Z",
     "start_time": "2019-11-25T18:00:38.376393Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "train_data = feature_train.drop(['is_30days_overdue'], axis=1)\n",
    "train_target = feature_train['is_30days_overdue']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.25, random_state=1)\n",
    "from sklearn.externals import joblib\n",
    "clf = joblib.load('DTC_changef1_66.m')\n",
    "\n",
    "# clf = clf.fit(train_data,train_target)\n",
    "print(clf)\n",
    "y_DT = clf.predict(feature)\n",
    "# f1_score(y_test,y_pridict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:00:40.576354Z",
     "start_time": "2019-11-25T18:00:40.567378Z"
    }
   },
   "outputs": [],
   "source": [
    "y_DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
    "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
    "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
    "       0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
    "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
    "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
    "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
    "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
    "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
    "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
    "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
    "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:00:43.715035Z",
     "start_time": "2019-11-25T18:00:43.703565Z"
    }
   },
   "outputs": [],
   "source": [
    "str(y_DT).count('0')\n",
    "str(y_DT).count('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T18:24:24.556589Z",
     "start_time": "2019-11-22T18:24:24.546592Z"
    }
   },
   "outputs": [],
   "source": [
    "before_=np.array([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T18:24:41.087752Z",
     "start_time": "2019-11-22T18:24:41.078742Z"
    }
   },
   "outputs": [],
   "source": [
    "str(before_).count('0')\n",
    "str(before_).count('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:01:17.417628Z",
     "start_time": "2019-11-25T18:01:17.404508Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_DT = pd.DataFrame()\n",
    "print(df_DT)\n",
    "df_DT.insert(0, 'y_predict', y_DT)\n",
    "df_DT.insert(0, 'apply_id', merge_loan['apply_id'].tolist())\n",
    "df_DT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:01:21.454176Z",
     "start_time": "2019-11-25T18:01:21.444204Z"
    }
   },
   "outputs": [],
   "source": [
    "df_DT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:02:00.270462Z",
     "start_time": "2019-11-25T18:02:00.261891Z"
    }
   },
   "outputs": [],
   "source": [
    "df_DT.to_csv('DT_predict_changef1_1125.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:02:27.923480Z",
     "start_time": "2019-11-25T18:02:27.912509Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "train_data = feature_train.drop(['is_30days_overdue'], axis=1)\n",
    "train_target = feature_train['is_30days_overdue']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.25, random_state=1)\n",
    "# clf = AdaBoostClassifier(algorithm='SAMME.R',\n",
    "#           base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "#             max_features=15, max_leaf_nodes=None,\n",
    "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#             min_samples_leaf=2, min_samples_split=12,\n",
    "#             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "#             splitter='random'),\n",
    "#           learning_rate=1.0, n_estimators=1, random_state=None)\n",
    "from sklearn.externals import joblib\n",
    "clf = joblib.load('ABC_changef1_66.m')\n",
    "# clf = clf.fit(train_data,train_target)\n",
    "print(clf)\n",
    "y_AB = clf.predict(feature.values)\n",
    "# f1_score(y_test,y_pridict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:02:30.709166Z",
     "start_time": "2019-11-25T18:02:30.698195Z"
    }
   },
   "outputs": [],
   "source": [
    "y_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:02:33.151899Z",
     "start_time": "2019-11-25T18:02:33.138896Z"
    }
   },
   "outputs": [],
   "source": [
    "str(y_AB).count('0')\n",
    "str(y_AB).count('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:02:45.475385Z",
     "start_time": "2019-11-25T18:02:45.462420Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_AB = pd.DataFrame()\n",
    "print(df_AB)\n",
    "df_AB.insert(0, 'y_predict', y_AB)\n",
    "df_AB.insert(0, 'apply_id', merge_loan['apply_id'].tolist())\n",
    "df_AB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:03:02.482240Z",
     "start_time": "2019-11-25T18:03:02.473853Z"
    }
   },
   "outputs": [],
   "source": [
    "df_AB.to_csv('ABC_predict_changef1_1125.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:52:48.371078Z",
     "start_time": "2019-12-15T13:52:48.244855Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=250, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=None, subsample=1, verbosity=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708267</td>\n",
       "      <td>0.561611</td>\n",
       "      <td>0.116594</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>0.681788</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207351</td>\n",
       "      <td>0.762552</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.935056</td>\n",
       "      <td>0.473908</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757589</td>\n",
       "      <td>0.744346</td>\n",
       "      <td>0.372269</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.996128</td>\n",
       "      <td>0.712411</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.818146</td>\n",
       "      <td>0.088984</td>\n",
       "      <td>0.116402</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.348594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548158</td>\n",
       "      <td>0.794644</td>\n",
       "      <td>0.320512</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>0.764678</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.711933</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.449864</td>\n",
       "      <td>0.361470</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838826</td>\n",
       "      <td>0.784040</td>\n",
       "      <td>0.332435</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.856913</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.932021</td>\n",
       "      <td>0.821560</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.677505</td>\n",
       "      <td>0.565122</td>\n",
       "      <td>0.172372</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.991337</td>\n",
       "      <td>0.731782</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.738287</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.904829</td>\n",
       "      <td>0.481249</td>\n",
       "      <td>0.156962</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.685003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737560</td>\n",
       "      <td>0.610681</td>\n",
       "      <td>0.271281</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.969885</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691458</td>\n",
       "      <td>0.772912</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.891572</td>\n",
       "      <td>0.420009</td>\n",
       "      <td>0.114014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488854</td>\n",
       "      <td>0.770418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.594147</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.595828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.496544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.612580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844267</td>\n",
       "      <td>0.585341</td>\n",
       "      <td>0.137174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986872</td>\n",
       "      <td>0.792070</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.984555</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.172561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756071</td>\n",
       "      <td>0.902783</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.791299</td>\n",
       "      <td>0.207351</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.792487</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.480303</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805717</td>\n",
       "      <td>0.967967</td>\n",
       "      <td>0.267214</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845970</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.818018</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.208855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.585275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903136</td>\n",
       "      <td>0.767887</td>\n",
       "      <td>0.193427</td>\n",
       "      <td>0.250805</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.876694</td>\n",
       "      <td>0.590105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.918974</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.904527</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.617630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900688</td>\n",
       "      <td>0.571007</td>\n",
       "      <td>0.215829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986701</td>\n",
       "      <td>0.870635</td>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.968058</td>\n",
       "      <td>0.325189</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.673947</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.533822</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.267675</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.996558</td>\n",
       "      <td>0.535109</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.583387</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.622408</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800873</td>\n",
       "      <td>0.893092</td>\n",
       "      <td>0.439033</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.815644</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.484444</td>\n",
       "      <td>0.248172</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.791434</td>\n",
       "      <td>0.750219</td>\n",
       "      <td>0.182442</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.990046</td>\n",
       "      <td>0.756473</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.818474</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.745378</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690290</td>\n",
       "      <td>0.694967</td>\n",
       "      <td>0.864225</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.956956</td>\n",
       "      <td>0.656154</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.703082</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.826412</td>\n",
       "      <td>0.562654</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.397908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784968</td>\n",
       "      <td>0.688212</td>\n",
       "      <td>0.414548</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.747255</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.806658</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.893543</td>\n",
       "      <td>0.764757</td>\n",
       "      <td>0.134513</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.573243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.852850</td>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.320242</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>0.832371</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.869076</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.651275</td>\n",
       "      <td>0.398468</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.681384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524831</td>\n",
       "      <td>0.882345</td>\n",
       "      <td>0.251150</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.596954</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.764726</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.190521</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.641160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.566994</td>\n",
       "      <td>0.055506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>0.750427</td>\n",
       "      <td>0.607528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.818207</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.943104</td>\n",
       "      <td>0.573588</td>\n",
       "      <td>0.128899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842274</td>\n",
       "      <td>0.867749</td>\n",
       "      <td>0.305272</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.819012</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.835493</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.822833</td>\n",
       "      <td>0.657442</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.662259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880060</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130824</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.858265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684711</td>\n",
       "      <td>0.793431</td>\n",
       "      <td>0.334058</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.669342</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.271164</td>\n",
       "      <td>0.136932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.878728</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.881272</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.851913</td>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.885955</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.959912</td>\n",
       "      <td>0.818574</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.751746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867264</td>\n",
       "      <td>0.773250</td>\n",
       "      <td>0.162704</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.827077</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.879848</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.918994</td>\n",
       "      <td>0.796086</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.348594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665150</td>\n",
       "      <td>0.720398</td>\n",
       "      <td>0.384608</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.997131</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.766073</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.891957</td>\n",
       "      <td>0.725929</td>\n",
       "      <td>0.106509</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802820</td>\n",
       "      <td>0.651355</td>\n",
       "      <td>0.592443</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.991960</td>\n",
       "      <td>0.722623</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.665562</td>\n",
       "      <td>0.839251</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.933723</td>\n",
       "      <td>0.562636</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.579348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402320</td>\n",
       "      <td>0.811666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.488975</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.767371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337654</td>\n",
       "      <td>0.085388</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.622557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868949</td>\n",
       "      <td>0.727781</td>\n",
       "      <td>0.286405</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.840584</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.885828</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.973841</td>\n",
       "      <td>0.534772</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.524492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948330</td>\n",
       "      <td>0.778755</td>\n",
       "      <td>0.195388</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.924436</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.960636</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.924766</td>\n",
       "      <td>0.709432</td>\n",
       "      <td>0.112976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.187367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854051</td>\n",
       "      <td>0.571048</td>\n",
       "      <td>0.368295</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.988211</td>\n",
       "      <td>0.809936</td>\n",
       "      <td>0.717866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.867749</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.992512</td>\n",
       "      <td>0.341148</td>\n",
       "      <td>0.091013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.449298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907620</td>\n",
       "      <td>0.760763</td>\n",
       "      <td>0.401496</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.998535</td>\n",
       "      <td>0.875133</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869176</td>\n",
       "      <td>0.921479</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.926623</td>\n",
       "      <td>0.786051</td>\n",
       "      <td>0.129102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.664994</td>\n",
       "      <td>0.892236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808225</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.659761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.621394</td>\n",
       "      <td>0.660962</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.949518</td>\n",
       "      <td>0.585898</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130824</td>\n",
       "      <td>0.649156</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.682660</td>\n",
       "      <td>0.233373</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867580</td>\n",
       "      <td>0.907041</td>\n",
       "      <td>0.337651</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.856396</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207351</td>\n",
       "      <td>0.854455</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.350560</td>\n",
       "      <td>0.116025</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.329105</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.950386</td>\n",
       "      <td>0.597660</td>\n",
       "      <td>0.064165</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.991873</td>\n",
       "      <td>0.929320</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>0.329088</td>\n",
       "      <td>0.105905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771853</td>\n",
       "      <td>0.595777</td>\n",
       "      <td>0.313341</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.989070</td>\n",
       "      <td>0.721378</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.734539</td>\n",
       "      <td>0.797784</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.880013</td>\n",
       "      <td>0.280950</td>\n",
       "      <td>0.121321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.470843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546687</td>\n",
       "      <td>0.539435</td>\n",
       "      <td>0.167604</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.892163</td>\n",
       "      <td>0.494345</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.585508</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.943470</td>\n",
       "      <td>0.558372</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.141738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832337</td>\n",
       "      <td>0.632609</td>\n",
       "      <td>0.069059</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.994558</td>\n",
       "      <td>0.784021</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.855458</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.932616</td>\n",
       "      <td>0.736905</td>\n",
       "      <td>0.128921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.187367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843541</td>\n",
       "      <td>0.963196</td>\n",
       "      <td>0.132903</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>0.057359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.557894</td>\n",
       "      <td>0.204883</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.984007</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.802254</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.934973</td>\n",
       "      <td>0.378699</td>\n",
       "      <td>0.143611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.702197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922854</td>\n",
       "      <td>0.756640</td>\n",
       "      <td>0.092341</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.899023</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.935889</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.928423</td>\n",
       "      <td>0.622990</td>\n",
       "      <td>0.115562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.224649</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.891864</td>\n",
       "      <td>0.573589</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.988460</td>\n",
       "      <td>0.863050</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.908509</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.952519</td>\n",
       "      <td>0.641922</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.325975</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.998283</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.745109</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.686226</td>\n",
       "      <td>0.683219</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.553754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671623</td>\n",
       "      <td>0.600914</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.996984</td>\n",
       "      <td>0.709882</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.711235</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.806363</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.366387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772901</td>\n",
       "      <td>0.783439</td>\n",
       "      <td>0.642750</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.989284</td>\n",
       "      <td>0.794400</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.796447</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.786657</td>\n",
       "      <td>0.551717</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.805992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675103</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>0.387475</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.674527</td>\n",
       "      <td>0.717866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.724213</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.929337</td>\n",
       "      <td>0.761521</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.366387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713785</td>\n",
       "      <td>0.867743</td>\n",
       "      <td>0.120038</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819002</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.731764</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.418210</td>\n",
       "      <td>0.160906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790799</td>\n",
       "      <td>0.970059</td>\n",
       "      <td>0.238670</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.903164</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.822854</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.203837</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.366387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808079</td>\n",
       "      <td>0.762305</td>\n",
       "      <td>0.189625</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.999493</td>\n",
       "      <td>0.766093</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.830024</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.808522</td>\n",
       "      <td>0.587699</td>\n",
       "      <td>0.122563</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883241</td>\n",
       "      <td>0.755180</td>\n",
       "      <td>0.127736</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.998805</td>\n",
       "      <td>0.848593</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.895987</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.144381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.759367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641615</td>\n",
       "      <td>0.532932</td>\n",
       "      <td>0.218825</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.707181</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261648</td>\n",
       "      <td>0.637747</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.948854</td>\n",
       "      <td>0.874136</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773521</td>\n",
       "      <td>0.594988</td>\n",
       "      <td>0.368544</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.978553</td>\n",
       "      <td>0.714732</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.773569</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.906602</td>\n",
       "      <td>0.190579</td>\n",
       "      <td>0.079227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.882859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843554</td>\n",
       "      <td>0.642273</td>\n",
       "      <td>0.377568</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.990522</td>\n",
       "      <td>0.792770</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730647</td>\n",
       "      <td>0.852838</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.941422</td>\n",
       "      <td>0.377911</td>\n",
       "      <td>0.167361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.566951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.787257</td>\n",
       "      <td>0.754321</td>\n",
       "      <td>0.220330</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0.742407</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.808391</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.962147</td>\n",
       "      <td>0.827006</td>\n",
       "      <td>0.079295</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.695492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808400</td>\n",
       "      <td>0.706901</td>\n",
       "      <td>0.661120</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.791970</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261648</td>\n",
       "      <td>0.838312</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.935918</td>\n",
       "      <td>0.420144</td>\n",
       "      <td>0.163424</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.348594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501019</td>\n",
       "      <td>0.646947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608932</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.280777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.714981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832357</td>\n",
       "      <td>0.619384</td>\n",
       "      <td>0.554823</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.987572</td>\n",
       "      <td>0.765210</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.827060</td>\n",
       "      <td>0.823754</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.905278</td>\n",
       "      <td>0.363864</td>\n",
       "      <td>0.042290</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.470843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809020</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.325633</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.954468</td>\n",
       "      <td>0.813148</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.817322</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.070542</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820631</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.271020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992258</td>\n",
       "      <td>0.768773</td>\n",
       "      <td>0.468999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.846885</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.954892</td>\n",
       "      <td>0.579944</td>\n",
       "      <td>0.097060</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0    0.283476  0.000000  0.708267  0.561611  0.116594  0.342857  0.989301   \n",
       "1    0.082911  0.000000  0.757589  0.744346  0.372269  0.388000  0.996128   \n",
       "2    0.348594  0.000000  0.548158  0.794644  0.320512  0.388000  0.997082   \n",
       "3    0.141738  0.000000  0.838826  0.784040  0.332435  0.342857  0.998964   \n",
       "4    0.082911  0.000000  0.677505  0.565122  0.172372  0.229310  0.991337   \n",
       "5    0.685003  0.000000  0.737560  0.610681  0.271281  0.388000  0.969885   \n",
       "6    0.490332  0.000000  0.488854  0.770418  0.000000  0.342857  1.000000   \n",
       "7    0.612580  0.000000  0.844267  0.585341  0.137174  0.000000  0.986872   \n",
       "8    0.307560  0.000000  0.756071  0.902783  0.201353  0.200000  0.999581   \n",
       "9    0.412016  0.000000  0.805717  0.967967  0.267214  0.800000  1.000000   \n",
       "10   0.585275  0.000000  0.903136  0.767887  0.193427  0.250805  0.999134   \n",
       "11   0.617630  0.000000  0.900688  0.571007  0.215829  0.000000  0.986701   \n",
       "12   0.673947  0.058824  0.533822  0.582906  0.267675  0.229310  0.996558   \n",
       "13   0.425213  0.000000  0.800873  0.893092  0.439033  0.388000  0.999995   \n",
       "14   0.412016  0.117647  0.791434  0.750219  0.182442  0.388000  0.990046   \n",
       "15   0.412016  0.000000  0.690290  0.694967  0.864225  0.229310  0.956956   \n",
       "16   0.397908  0.000000  0.784968  0.688212  0.414548  0.200000  0.996205   \n",
       "17   0.573243  0.000000  0.852850  0.896178  0.320242  0.388000  0.990873   \n",
       "18   0.681384  0.000000  0.524831  0.882345  0.251150  0.388000  0.999136   \n",
       "19   0.641160  0.000000  0.800412  0.566994  0.055506  0.000000  0.986894   \n",
       "20   0.256170  0.000000  0.842274  0.867749  0.305272  0.350000  0.999942   \n",
       "21   0.662259  0.000000  1.000000  0.880060  0.085584  0.229310  0.999994   \n",
       "22   0.627369  0.000000  0.684711  0.793431  0.334058  0.229310  1.000000   \n",
       "23   0.878728  0.058824  0.881272  0.772738  0.123800  0.200000  0.999602   \n",
       "24   0.751746  0.000000  0.867264  0.773250  0.162704  0.342857  0.999425   \n",
       "25   0.348594  0.000000  0.665150  0.720398  0.384608  0.342857  0.997131   \n",
       "26   0.490332  0.000000  0.802820  0.651355  0.592443  0.388000  0.991960   \n",
       "27   0.579348  0.000000  0.402320  0.811666  0.000000  0.388000  0.999856   \n",
       "28   0.622557  0.000000  0.868949  0.727781  0.286405  0.229310  0.998340   \n",
       "29   0.524492  0.000000  0.948330  0.778755  0.195388  0.229310  0.999351   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "423  0.187367  0.000000  0.854051  0.571048  0.368295  0.066667  0.988211   \n",
       "424  0.449298  0.000000  0.907620  0.760763  0.401496  0.200000  0.998535   \n",
       "425  0.082911  0.000000  0.664994  0.892236  0.000000  0.342857  1.000000   \n",
       "426  0.425213  0.000000  0.590600  0.621394  0.660962  0.388000  0.949518   \n",
       "427  0.627369  0.000000  0.867580  0.907041  0.337651  0.388000  0.999712   \n",
       "428  0.329105  0.058824  0.950386  0.597660  0.064165  0.342857  0.991873   \n",
       "429  0.425213  0.000000  0.771853  0.595777  0.313341  0.388000  0.989070   \n",
       "430  0.470843  0.000000  0.546687  0.539435  0.167604  0.388000  0.892163   \n",
       "431  0.141738  0.000000  0.832337  0.632609  0.069059  0.229310  0.994558   \n",
       "432  0.187367  0.000000  0.843541  0.963196  0.132903  0.200000  1.000000   \n",
       "433  0.425213  0.000000  0.785185  0.557894  0.204883  0.229310  0.984007   \n",
       "434  0.702197  0.000000  0.922854  0.756640  0.092341  0.229310  0.999300   \n",
       "435  0.224649  0.294118  0.891864  0.573589  0.043547  0.229310  0.988460   \n",
       "436  0.490332  0.000000  0.768056  0.704433  0.325975  0.350000  0.998283   \n",
       "437  0.553754  0.000000  0.671623  0.600914  0.110740  0.229310  0.996984   \n",
       "438  0.366387  0.000000  0.772901  0.783439  0.642750  0.229310  0.989284   \n",
       "439  0.805992  0.000000  0.675103  0.718502  0.387475  0.066667  0.992965   \n",
       "440  0.366387  0.000000  0.713785  0.867743  0.120038  0.342857  1.000000   \n",
       "441  0.307560  0.000000  0.790799  0.970059  0.238670  0.388000  0.999956   \n",
       "442  0.366387  0.000000  0.808079  0.762305  0.189625  0.200000  0.999493   \n",
       "443  0.307560  0.000000  0.883241  0.755180  0.127736  0.229310  0.998805   \n",
       "444  0.759367  0.000000  0.641615  0.532932  0.218825  0.229310  0.998826   \n",
       "445  0.412016  0.000000  0.773521  0.594988  0.368544  0.388000  0.978553   \n",
       "446  0.882859  0.000000  0.843554  0.642273  0.377568  0.200000  0.990522   \n",
       "447  0.566951  0.000000  0.787257  0.754321  0.220330  0.229310  0.998454   \n",
       "448  0.695492  0.000000  0.808400  0.706901  0.661120  0.229310  0.978653   \n",
       "449  0.348594  0.000000  0.501019  0.646947  0.000000  0.388000  1.000000   \n",
       "450  0.714981  0.000000  0.832357  0.619384  0.554823  0.388000  0.987572   \n",
       "451  0.470843  0.000000  0.809020  0.903587  0.325633  0.200000  0.954468   \n",
       "452  0.425213  0.000000  0.820631  0.641304  0.271020  1.000000  0.992258   \n",
       "\n",
       "           f7        f8        f9       f10       f11       f12       f13  \\\n",
       "0    0.681788  0.585836  0.000000  1.000000  0.207351  0.762552  0.189189   \n",
       "1    0.712411  0.567290  0.000000  0.454545  0.434588  0.784500  0.310811   \n",
       "2    0.764678  0.567290  0.000000  0.181818  0.303764  0.711933  0.040541   \n",
       "3    0.805407  0.585836  0.000000  1.000000  0.738352  0.856913  0.797297   \n",
       "4    0.731782  0.602248  0.144928  0.181818  0.303764  0.738287  0.040541   \n",
       "5    0.694447  0.567290  0.000000  1.000000  0.691458  0.772912  0.891892   \n",
       "6    0.594147  0.585836  0.115942  0.727273  0.303764  0.595828  0.000000   \n",
       "7    0.792070  0.738352  0.000000  0.272727  0.738352  0.855037  0.689189   \n",
       "8    0.791299  0.207351  0.014493  1.000000  0.434588  0.792487  0.135135   \n",
       "9    0.845970  0.392472  0.202899  0.454545  0.303764  0.818018  0.108108   \n",
       "10   0.876694  0.590105  0.000000  0.272727  0.738352  0.918974  0.864865   \n",
       "11   0.870635  0.641939  0.000000  1.000000  0.738352  0.910283  0.405405   \n",
       "12   0.535109  0.602248  0.246377  0.454545  0.303764  0.583387  0.243243   \n",
       "13   0.867200  0.567290  0.057971  0.454545  0.565412  0.815644  0.148649   \n",
       "14   0.756473  0.567290  0.000000  0.000000  0.738352  0.818474  0.513514   \n",
       "15   0.656154  0.602248  0.028986  0.181818  0.392472  0.703082  0.229730   \n",
       "16   0.747255  0.452577  0.000000  0.727273  0.511115  0.806658  0.459459   \n",
       "17   0.832371  0.567290  0.000000  0.363636  0.738352  0.869076  0.554054   \n",
       "18   0.596954  0.567290  0.000000  1.000000  0.511115  0.764726  0.040541   \n",
       "19   0.750427  0.607528  0.000000  0.181818  0.434588  0.818207  0.405405   \n",
       "20   0.819012  0.392472  0.000000  0.454545  0.303764  0.835493  0.337838   \n",
       "21   1.000000  0.602248  0.000000  1.000000  0.130824  0.982891  0.337838   \n",
       "22   0.744884  0.602248  0.028986  0.181818  0.303764  0.669342  0.040541   \n",
       "23   0.851913  0.565412  0.000000  0.181818  0.303764  0.885955  0.567568   \n",
       "24   0.827077  0.585836  0.000000  0.454545  0.738352  0.879848  0.797297   \n",
       "25   0.649485  0.585836  0.000000  0.454545  0.303764  0.766073  0.216216   \n",
       "26   0.722623  0.567290  0.000000  0.454545  0.665562  0.839251  0.824324   \n",
       "27   0.488975  0.567290  0.000000  0.181818  0.303764  0.767371  0.000000   \n",
       "28   0.840584  0.602248  0.000000  1.000000  0.738352  0.885828  0.581081   \n",
       "29   0.924436  0.602248  0.000000  0.181818  0.565412  0.960636  0.459459   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "423  0.809936  0.717866  0.000000  0.454545  0.641939  0.867749  0.486486   \n",
       "424  0.875133  0.452577  0.000000  0.000000  0.869176  0.921479  0.878378   \n",
       "425  0.808225  0.585836  0.318841  1.000000  0.303764  0.659761  0.000000   \n",
       "426  0.585898  0.567290  0.000000  1.000000  0.130824  0.649156  0.378378   \n",
       "427  0.856396  0.567290  0.000000  1.000000  0.207351  0.854455  0.256757   \n",
       "428  0.929320  0.585836  0.000000  0.000000  0.738352  0.968296  0.486486   \n",
       "429  0.721378  0.567290  0.000000  0.454545  0.734539  0.797784  0.756757   \n",
       "430  0.494345  0.567290  0.000000  1.000000  0.434588  0.585508  0.175676   \n",
       "431  0.784021  0.602248  0.000000  0.181818  0.738352  0.855458  0.756757   \n",
       "432  0.880795  0.452577  0.000000  0.454545  0.392472  0.863277  0.256757   \n",
       "433  0.724362  0.602248  0.000000  0.818182  0.303764  0.802254  0.702703   \n",
       "434  0.899023  0.602248  0.000000  0.454545  0.738352  0.935889  0.418919   \n",
       "435  0.863050  0.602248  0.000000  1.000000  0.738352  0.908509  0.513514   \n",
       "436  0.715596  0.392472  0.000000  0.454545  0.511115  0.745109  0.351351   \n",
       "437  0.709882  0.602248  0.043478  0.454545  0.511115  0.711235  0.054054   \n",
       "438  0.794400  0.602248  0.202899  0.454545  0.434588  0.796447  0.324324   \n",
       "439  0.674527  0.717866  0.000000  0.454545  0.511115  0.724213  0.324324   \n",
       "440  0.819002  0.585836  0.260870  0.181818  0.303764  0.731764  0.054054   \n",
       "441  0.903164  0.567290  0.333333  0.181818  0.434588  0.822854  0.067568   \n",
       "442  0.766093  0.452577  0.000000  0.454545  0.641939  0.830024  0.797297   \n",
       "443  0.848593  0.602248  0.000000  1.000000  0.738352  0.895987  0.810811   \n",
       "444  0.707181  0.602248  0.101449  1.000000  0.261648  0.637747  0.027027   \n",
       "445  0.714732  0.567290  0.000000  0.727273  0.434588  0.773569  0.418919   \n",
       "446  0.792770  0.452577  0.000000  1.000000  0.730647  0.852838  0.986486   \n",
       "447  0.742407  0.602248  0.000000  0.454545  0.738352  0.808391  0.810811   \n",
       "448  0.791970  0.602248  0.000000  1.000000  0.261648  0.838312  0.702703   \n",
       "449  0.608932  0.567290  0.144928  0.181818  0.000000  0.553836  0.000000   \n",
       "450  0.765210  0.567290  0.000000  0.272727  0.827060  0.823754  0.756757   \n",
       "451  0.813148  0.452577  0.000000  0.454545  0.434588  0.817322  0.175676   \n",
       "452  0.768773  0.468999  0.000000  0.181818  0.565412  0.846885  0.472973   \n",
       "\n",
       "          f14       f15       f16       f17       f18  \n",
       "0    0.935056  0.473908  0.105426  0.626667  0.024390  \n",
       "1    0.818146  0.088984  0.116402  0.773333  0.000000  \n",
       "2    0.449864  0.361470  0.146341  0.160000  0.024390  \n",
       "3    0.932021  0.821560  0.126582  0.973333  0.024390  \n",
       "4    0.904829  0.481249  0.156962  0.226667  0.000000  \n",
       "5    0.891572  0.420009  0.114014  1.000000  0.024390  \n",
       "6    0.328704  0.496544  0.000000  0.026667  0.048780  \n",
       "7    0.984555  0.446453  0.172561  1.000000  0.000000  \n",
       "8    0.688172  0.480303  0.064516  0.226667  0.000000  \n",
       "9    0.309524  0.208855  0.000000  0.133333  0.000000  \n",
       "10   0.904527  0.685529  0.105706  0.986667  0.146341  \n",
       "11   0.968058  0.325189  0.081866  1.000000  0.170732  \n",
       "12   0.899306  0.622408  0.125000  0.293333  0.024390  \n",
       "13   0.484444  0.248172  0.026667  0.146667  0.000000  \n",
       "14   0.783951  0.745378  0.051724  0.893333  0.073171  \n",
       "15   0.826412  0.562654  0.040404  0.293333  0.024390  \n",
       "16   0.893543  0.764757  0.134513  0.946667  0.000000  \n",
       "17   0.651275  0.398468  0.116883  0.706667  0.073171  \n",
       "18   0.283951  0.190521  0.039216  0.146667  0.024390  \n",
       "19   0.943104  0.573588  0.128899  1.000000  0.048780  \n",
       "20   0.822833  0.657442  0.020619  0.560000  0.000000  \n",
       "21   0.858265  0.000000  0.007628  0.520000  0.097561  \n",
       "22   0.271164  0.136932  0.000000  0.080000  0.000000  \n",
       "23   0.959912  0.818574  0.018018  0.800000  0.073171  \n",
       "24   0.918994  0.796086  0.075419  1.000000  0.000000  \n",
       "25   0.891957  0.725929  0.106509  0.773333  0.048780  \n",
       "26   0.933723  0.562636  0.137931  0.986667  0.000000  \n",
       "27   0.337654  0.085388  0.016667  0.213333  0.000000  \n",
       "28   0.973841  0.534772  0.011461  1.000000  0.048780  \n",
       "29   0.924766  0.709432  0.112976  1.000000  0.195122  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "423  0.992512  0.341148  0.091013  1.000000  0.048780  \n",
       "424  0.926623  0.786051  0.129102  1.000000  0.048780  \n",
       "425  0.121212  0.267700  0.000000  0.013333  0.000000  \n",
       "426  0.682660  0.233373  0.068182  0.493333  0.000000  \n",
       "427  0.350560  0.116025  0.023256  0.440000  0.048780  \n",
       "428  0.990923  0.329088  0.105905  1.000000  0.097561  \n",
       "429  0.880013  0.280950  0.121321  1.000000  0.097561  \n",
       "430  0.943470  0.558372  0.140351  0.466667  0.024390  \n",
       "431  0.932616  0.736905  0.128921  1.000000  0.000000  \n",
       "432  0.794326  0.057359  0.000000  0.280000  0.000000  \n",
       "433  0.934973  0.378699  0.143611  1.000000  0.000000  \n",
       "434  0.928423  0.622990  0.115562  1.000000  0.243902  \n",
       "435  0.952519  0.641922  0.126900  1.000000  0.195122  \n",
       "436  0.686226  0.683219  0.089888  0.440000  0.000000  \n",
       "437  0.913623  0.806363  0.146853  0.253333  0.048780  \n",
       "438  0.786657  0.551717  0.246575  0.320000  0.024390  \n",
       "439  0.929337  0.761521  0.184211  0.560000  0.000000  \n",
       "440  0.418210  0.160906  0.000000  0.053333  0.024390  \n",
       "441  0.325581  0.203837  0.046512  0.146667  0.024390  \n",
       "442  0.808522  0.587699  0.122563  0.960000  0.024390  \n",
       "443  0.940084  0.759630  0.144381  1.000000  0.097561  \n",
       "444  0.948854  0.874136  0.035714  0.066667  0.000000  \n",
       "445  0.906602  0.190579  0.079227  1.000000  0.024390  \n",
       "446  0.941422  0.377911  0.167361  1.000000  0.073171  \n",
       "447  0.962147  0.827006  0.079295  0.906667  0.048780  \n",
       "448  0.935918  0.420144  0.163424  0.960000  0.024390  \n",
       "449  0.283951  0.280777  0.000000  0.013333  0.024390  \n",
       "450  0.905278  0.363864  0.042290  0.986667  0.073171  \n",
       "451  0.188811  0.070542  0.027972  0.293333  0.073171  \n",
       "452  0.954892  0.579944  0.097060  0.920000  0.097561  \n",
       "\n",
       "[453 rows x 19 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_sum_send_amount</th>\n",
       "      <th>lend_period</th>\n",
       "      <th>view_no</th>\n",
       "      <th>sum_his_lend_amount</th>\n",
       "      <th>mean_his_overdue_times</th>\n",
       "      <th>sum_before_30_trans_amount</th>\n",
       "      <th>mean_every_day_trans_amount</th>\n",
       "      <th>cv_mean_every_day_trans_amount</th>\n",
       "      <th>sum_every_trans_amount</th>\n",
       "      <th>on_sale_rate</th>\n",
       "      <th>sum_before_30_trans_count</th>\n",
       "      <th>sum_every_trans_count</th>\n",
       "      <th>nearest_trans_day</th>\n",
       "      <th>mean_every_trans_trans_amount</th>\n",
       "      <th>mean_good_status</th>\n",
       "      <th>store_num</th>\n",
       "      <th>terminal_num</th>\n",
       "      <th>on_sale_or_not</th>\n",
       "      <th>mean_payer_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283476</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.708267</td>\n",
       "      <td>0.681788</td>\n",
       "      <td>0.116594</td>\n",
       "      <td>0.762552</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561611</td>\n",
       "      <td>0.935056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.473908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.757589</td>\n",
       "      <td>0.712411</td>\n",
       "      <td>0.372269</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.996128</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744346</td>\n",
       "      <td>0.818146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116402</td>\n",
       "      <td>0.088984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.348594</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.548158</td>\n",
       "      <td>0.764678</td>\n",
       "      <td>0.320512</td>\n",
       "      <td>0.711933</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.794644</td>\n",
       "      <td>0.449864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.361470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141738</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.838826</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.332435</td>\n",
       "      <td>0.856913</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784040</td>\n",
       "      <td>0.932021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.821560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.677505</td>\n",
       "      <td>0.731782</td>\n",
       "      <td>0.172372</td>\n",
       "      <td>0.738287</td>\n",
       "      <td>0.991337</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.565122</td>\n",
       "      <td>0.904829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156962</td>\n",
       "      <td>0.481249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.691458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685003</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.737560</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>0.271281</td>\n",
       "      <td>0.772912</td>\n",
       "      <td>0.969885</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610681</td>\n",
       "      <td>0.891572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.114014</td>\n",
       "      <td>0.420009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.488854</td>\n",
       "      <td>0.594147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.595828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.770418</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.612580</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844267</td>\n",
       "      <td>0.792070</td>\n",
       "      <td>0.137174</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>0.986872</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585341</td>\n",
       "      <td>0.984555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172561</td>\n",
       "      <td>0.446453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.207351</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.756071</td>\n",
       "      <td>0.791299</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>0.792487</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.902783</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.480303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.805717</td>\n",
       "      <td>0.845970</td>\n",
       "      <td>0.267214</td>\n",
       "      <td>0.818018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.967967</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.585275</td>\n",
       "      <td>0.590105</td>\n",
       "      <td>0.250805</td>\n",
       "      <td>0.903136</td>\n",
       "      <td>0.876694</td>\n",
       "      <td>0.193427</td>\n",
       "      <td>0.918974</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767887</td>\n",
       "      <td>0.904527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.685529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617630</td>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900688</td>\n",
       "      <td>0.870635</td>\n",
       "      <td>0.215829</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>0.986701</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571007</td>\n",
       "      <td>0.968058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.325189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.533822</td>\n",
       "      <td>0.535109</td>\n",
       "      <td>0.267675</td>\n",
       "      <td>0.583387</td>\n",
       "      <td>0.996558</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.622408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.800873</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.439033</td>\n",
       "      <td>0.815644</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.893092</td>\n",
       "      <td>0.484444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.248172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.791434</td>\n",
       "      <td>0.756473</td>\n",
       "      <td>0.182442</td>\n",
       "      <td>0.818474</td>\n",
       "      <td>0.990046</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750219</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.745378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.690290</td>\n",
       "      <td>0.656154</td>\n",
       "      <td>0.864225</td>\n",
       "      <td>0.703082</td>\n",
       "      <td>0.956956</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.694967</td>\n",
       "      <td>0.826412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.562654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.397908</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.784968</td>\n",
       "      <td>0.747255</td>\n",
       "      <td>0.414548</td>\n",
       "      <td>0.806658</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688212</td>\n",
       "      <td>0.893543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134513</td>\n",
       "      <td>0.764757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.573243</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.852850</td>\n",
       "      <td>0.832371</td>\n",
       "      <td>0.320242</td>\n",
       "      <td>0.869076</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.651275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.398468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.511115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681384</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.524831</td>\n",
       "      <td>0.596954</td>\n",
       "      <td>0.251150</td>\n",
       "      <td>0.764726</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882345</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.190521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.641160</td>\n",
       "      <td>0.607528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.750427</td>\n",
       "      <td>0.055506</td>\n",
       "      <td>0.818207</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566994</td>\n",
       "      <td>0.943104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.128899</td>\n",
       "      <td>0.573588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.256170</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.842274</td>\n",
       "      <td>0.819012</td>\n",
       "      <td>0.305272</td>\n",
       "      <td>0.835493</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867749</td>\n",
       "      <td>0.822833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.657442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.130824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.662259</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880060</td>\n",
       "      <td>0.858265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.684711</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.334058</td>\n",
       "      <td>0.669342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.793431</td>\n",
       "      <td>0.271164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.878728</td>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.881272</td>\n",
       "      <td>0.851913</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.885955</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>0.959912</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.818574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.751746</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.867264</td>\n",
       "      <td>0.827077</td>\n",
       "      <td>0.162704</td>\n",
       "      <td>0.879848</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773250</td>\n",
       "      <td>0.918994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>0.796086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.348594</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.665150</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.384608</td>\n",
       "      <td>0.766073</td>\n",
       "      <td>0.997131</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720398</td>\n",
       "      <td>0.891957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.106509</td>\n",
       "      <td>0.725929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.665562</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.802820</td>\n",
       "      <td>0.722623</td>\n",
       "      <td>0.592443</td>\n",
       "      <td>0.839251</td>\n",
       "      <td>0.991960</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651355</td>\n",
       "      <td>0.933723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.562636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.402320</td>\n",
       "      <td>0.488975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767371</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811666</td>\n",
       "      <td>0.337654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.085388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622557</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.868949</td>\n",
       "      <td>0.840584</td>\n",
       "      <td>0.286405</td>\n",
       "      <td>0.885828</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727781</td>\n",
       "      <td>0.973841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.534772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.524492</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.948330</td>\n",
       "      <td>0.924436</td>\n",
       "      <td>0.195388</td>\n",
       "      <td>0.960636</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778755</td>\n",
       "      <td>0.924766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.112976</td>\n",
       "      <td>0.709432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.187367</td>\n",
       "      <td>0.717866</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.854051</td>\n",
       "      <td>0.809936</td>\n",
       "      <td>0.368295</td>\n",
       "      <td>0.867749</td>\n",
       "      <td>0.988211</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571048</td>\n",
       "      <td>0.992512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.091013</td>\n",
       "      <td>0.341148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.869176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449298</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.907620</td>\n",
       "      <td>0.875133</td>\n",
       "      <td>0.401496</td>\n",
       "      <td>0.921479</td>\n",
       "      <td>0.998535</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760763</td>\n",
       "      <td>0.926623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.129102</td>\n",
       "      <td>0.786051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082911</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.664994</td>\n",
       "      <td>0.808225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.892236</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.130824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.585898</td>\n",
       "      <td>0.660962</td>\n",
       "      <td>0.649156</td>\n",
       "      <td>0.949518</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621394</td>\n",
       "      <td>0.682660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.233373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.207351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.867580</td>\n",
       "      <td>0.856396</td>\n",
       "      <td>0.337651</td>\n",
       "      <td>0.854455</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907041</td>\n",
       "      <td>0.350560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.116025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329105</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.950386</td>\n",
       "      <td>0.929320</td>\n",
       "      <td>0.064165</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>0.991873</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597660</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.105905</td>\n",
       "      <td>0.329088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.734539</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.771853</td>\n",
       "      <td>0.721378</td>\n",
       "      <td>0.313341</td>\n",
       "      <td>0.797784</td>\n",
       "      <td>0.989070</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.595777</td>\n",
       "      <td>0.880013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.121321</td>\n",
       "      <td>0.280950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470843</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.546687</td>\n",
       "      <td>0.494345</td>\n",
       "      <td>0.167604</td>\n",
       "      <td>0.585508</td>\n",
       "      <td>0.892163</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.539435</td>\n",
       "      <td>0.943470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.558372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.141738</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.832337</td>\n",
       "      <td>0.784021</td>\n",
       "      <td>0.069059</td>\n",
       "      <td>0.855458</td>\n",
       "      <td>0.994558</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632609</td>\n",
       "      <td>0.932616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128921</td>\n",
       "      <td>0.736905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.187367</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.843541</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.132903</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963196</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>0.204883</td>\n",
       "      <td>0.802254</td>\n",
       "      <td>0.984007</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557894</td>\n",
       "      <td>0.934973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143611</td>\n",
       "      <td>0.378699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.702197</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.922854</td>\n",
       "      <td>0.899023</td>\n",
       "      <td>0.092341</td>\n",
       "      <td>0.935889</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756640</td>\n",
       "      <td>0.928423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.115562</td>\n",
       "      <td>0.622990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.891864</td>\n",
       "      <td>0.863050</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.908509</td>\n",
       "      <td>0.988460</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573589</td>\n",
       "      <td>0.952519</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.641922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.325975</td>\n",
       "      <td>0.745109</td>\n",
       "      <td>0.998283</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.686226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.683219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.553754</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.671623</td>\n",
       "      <td>0.709882</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>0.711235</td>\n",
       "      <td>0.996984</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.600914</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.806363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.366387</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.772901</td>\n",
       "      <td>0.794400</td>\n",
       "      <td>0.642750</td>\n",
       "      <td>0.796447</td>\n",
       "      <td>0.989284</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.783439</td>\n",
       "      <td>0.786657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.551717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.805992</td>\n",
       "      <td>0.717866</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.675103</td>\n",
       "      <td>0.674527</td>\n",
       "      <td>0.387475</td>\n",
       "      <td>0.724213</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>0.929337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.761521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.366387</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.713785</td>\n",
       "      <td>0.819002</td>\n",
       "      <td>0.120038</td>\n",
       "      <td>0.731764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.867743</td>\n",
       "      <td>0.418210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.790799</td>\n",
       "      <td>0.903164</td>\n",
       "      <td>0.238670</td>\n",
       "      <td>0.822854</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.970059</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.203837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.366387</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.808079</td>\n",
       "      <td>0.766093</td>\n",
       "      <td>0.189625</td>\n",
       "      <td>0.830024</td>\n",
       "      <td>0.999493</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762305</td>\n",
       "      <td>0.808522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.122563</td>\n",
       "      <td>0.587699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.883241</td>\n",
       "      <td>0.848593</td>\n",
       "      <td>0.127736</td>\n",
       "      <td>0.895987</td>\n",
       "      <td>0.998805</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755180</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.144381</td>\n",
       "      <td>0.759630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.261648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759367</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.641615</td>\n",
       "      <td>0.707181</td>\n",
       "      <td>0.218825</td>\n",
       "      <td>0.637747</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.532932</td>\n",
       "      <td>0.948854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.874136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.412016</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.773521</td>\n",
       "      <td>0.714732</td>\n",
       "      <td>0.368544</td>\n",
       "      <td>0.773569</td>\n",
       "      <td>0.978553</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594988</td>\n",
       "      <td>0.906602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.079227</td>\n",
       "      <td>0.190579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.730647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882859</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.843554</td>\n",
       "      <td>0.792770</td>\n",
       "      <td>0.377568</td>\n",
       "      <td>0.852838</td>\n",
       "      <td>0.990522</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642273</td>\n",
       "      <td>0.941422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.167361</td>\n",
       "      <td>0.377911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.566951</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.787257</td>\n",
       "      <td>0.742407</td>\n",
       "      <td>0.220330</td>\n",
       "      <td>0.808391</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754321</td>\n",
       "      <td>0.962147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.079295</td>\n",
       "      <td>0.827006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.261648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695492</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.808400</td>\n",
       "      <td>0.791970</td>\n",
       "      <td>0.661120</td>\n",
       "      <td>0.838312</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.706901</td>\n",
       "      <td>0.935918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.163424</td>\n",
       "      <td>0.420144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.348594</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.501019</td>\n",
       "      <td>0.608932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.646947</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.827060</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.714981</td>\n",
       "      <td>0.567290</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.832357</td>\n",
       "      <td>0.765210</td>\n",
       "      <td>0.554823</td>\n",
       "      <td>0.823754</td>\n",
       "      <td>0.987572</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619384</td>\n",
       "      <td>0.905278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.042290</td>\n",
       "      <td>0.363864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.470843</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.809020</td>\n",
       "      <td>0.813148</td>\n",
       "      <td>0.325633</td>\n",
       "      <td>0.817322</td>\n",
       "      <td>0.954468</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.070542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.425213</td>\n",
       "      <td>0.468999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820631</td>\n",
       "      <td>0.768773</td>\n",
       "      <td>0.271020</td>\n",
       "      <td>0.846885</td>\n",
       "      <td>0.992258</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.954892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.097060</td>\n",
       "      <td>0.579944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log_sum_send_amount  lend_period   view_no  sum_his_lend_amount  \\\n",
       "0               0.207351     1.000000  0.283476             0.585836   \n",
       "1               0.434588     0.454545  0.082911             0.567290   \n",
       "2               0.303764     0.181818  0.348594             0.567290   \n",
       "3               0.738352     1.000000  0.141738             0.585836   \n",
       "4               0.303764     0.181818  0.082911             0.602248   \n",
       "5               0.691458     1.000000  0.685003             0.567290   \n",
       "6               0.303764     0.727273  0.490332             0.585836   \n",
       "7               0.738352     0.272727  0.612580             0.738352   \n",
       "8               0.434588     1.000000  0.307560             0.207351   \n",
       "9               0.303764     0.454545  0.412016             0.392472   \n",
       "10              0.738352     0.272727  0.585275             0.590105   \n",
       "11              0.738352     1.000000  0.617630             0.641939   \n",
       "12              0.303764     0.454545  0.673947             0.602248   \n",
       "13              0.565412     0.454545  0.425213             0.567290   \n",
       "14              0.738352     0.000000  0.412016             0.567290   \n",
       "15              0.392472     0.181818  0.412016             0.602248   \n",
       "16              0.511115     0.727273  0.397908             0.452577   \n",
       "17              0.738352     0.363636  0.573243             0.567290   \n",
       "18              0.511115     1.000000  0.681384             0.567290   \n",
       "19              0.434588     0.181818  0.641160             0.607528   \n",
       "20              0.303764     0.454545  0.256170             0.392472   \n",
       "21              0.130824     1.000000  0.662259             0.602248   \n",
       "22              0.303764     0.181818  0.627369             0.602248   \n",
       "23              0.303764     0.181818  0.878728             0.565412   \n",
       "24              0.738352     0.454545  0.751746             0.585836   \n",
       "25              0.303764     0.454545  0.348594             0.585836   \n",
       "26              0.665562     0.454545  0.490332             0.567290   \n",
       "27              0.303764     0.181818  0.579348             0.567290   \n",
       "28              0.738352     1.000000  0.622557             0.602248   \n",
       "29              0.565412     0.181818  0.524492             0.602248   \n",
       "..                   ...          ...       ...                  ...   \n",
       "423             0.641939     0.454545  0.187367             0.717866   \n",
       "424             0.869176     0.000000  0.449298             0.452577   \n",
       "425             0.303764     1.000000  0.082911             0.585836   \n",
       "426             0.130824     1.000000  0.425213             0.567290   \n",
       "427             0.207351     1.000000  0.627369             0.567290   \n",
       "428             0.738352     0.000000  0.329105             0.585836   \n",
       "429             0.734539     0.454545  0.425213             0.567290   \n",
       "430             0.434588     1.000000  0.470843             0.567290   \n",
       "431             0.738352     0.181818  0.141738             0.602248   \n",
       "432             0.392472     0.454545  0.187367             0.452577   \n",
       "433             0.303764     0.818182  0.425213             0.602248   \n",
       "434             0.738352     0.454545  0.702197             0.602248   \n",
       "435             0.738352     1.000000  0.224649             0.602248   \n",
       "436             0.511115     0.454545  0.490332             0.392472   \n",
       "437             0.511115     0.454545  0.553754             0.602248   \n",
       "438             0.434588     0.454545  0.366387             0.602248   \n",
       "439             0.511115     0.454545  0.805992             0.717866   \n",
       "440             0.303764     0.181818  0.366387             0.585836   \n",
       "441             0.434588     0.181818  0.307560             0.567290   \n",
       "442             0.641939     0.454545  0.366387             0.452577   \n",
       "443             0.738352     1.000000  0.307560             0.602248   \n",
       "444             0.261648     1.000000  0.759367             0.602248   \n",
       "445             0.434588     0.727273  0.412016             0.567290   \n",
       "446             0.730647     1.000000  0.882859             0.452577   \n",
       "447             0.738352     0.454545  0.566951             0.602248   \n",
       "448             0.261648     1.000000  0.695492             0.602248   \n",
       "449             0.000000     0.181818  0.348594             0.567290   \n",
       "450             0.827060     0.272727  0.714981             0.567290   \n",
       "451             0.434588     0.454545  0.470843             0.452577   \n",
       "452             0.565412     0.181818  0.425213             0.468999   \n",
       "\n",
       "     mean_his_overdue_times  sum_before_30_trans_amount  \\\n",
       "0                  0.342857                    0.708267   \n",
       "1                  0.388000                    0.757589   \n",
       "2                  0.388000                    0.548158   \n",
       "3                  0.342857                    0.838826   \n",
       "4                  0.229310                    0.677505   \n",
       "5                  0.388000                    0.737560   \n",
       "6                  0.342857                    0.488854   \n",
       "7                  0.000000                    0.844267   \n",
       "8                  0.200000                    0.756071   \n",
       "9                  0.800000                    0.805717   \n",
       "10                 0.250805                    0.903136   \n",
       "11                 0.000000                    0.900688   \n",
       "12                 0.229310                    0.533822   \n",
       "13                 0.388000                    0.800873   \n",
       "14                 0.388000                    0.791434   \n",
       "15                 0.229310                    0.690290   \n",
       "16                 0.200000                    0.784968   \n",
       "17                 0.388000                    0.852850   \n",
       "18                 0.388000                    0.524831   \n",
       "19                 0.000000                    0.800412   \n",
       "20                 0.350000                    0.842274   \n",
       "21                 0.229310                    1.000000   \n",
       "22                 0.229310                    0.684711   \n",
       "23                 0.200000                    0.881272   \n",
       "24                 0.342857                    0.867264   \n",
       "25                 0.342857                    0.665150   \n",
       "26                 0.388000                    0.802820   \n",
       "27                 0.388000                    0.402320   \n",
       "28                 0.229310                    0.868949   \n",
       "29                 0.229310                    0.948330   \n",
       "..                      ...                         ...   \n",
       "423                0.066667                    0.854051   \n",
       "424                0.200000                    0.907620   \n",
       "425                0.342857                    0.664994   \n",
       "426                0.388000                    0.590600   \n",
       "427                0.388000                    0.867580   \n",
       "428                0.342857                    0.950386   \n",
       "429                0.388000                    0.771853   \n",
       "430                0.388000                    0.546687   \n",
       "431                0.229310                    0.832337   \n",
       "432                0.200000                    0.843541   \n",
       "433                0.229310                    0.785185   \n",
       "434                0.229310                    0.922854   \n",
       "435                0.229310                    0.891864   \n",
       "436                0.350000                    0.768056   \n",
       "437                0.229310                    0.671623   \n",
       "438                0.229310                    0.772901   \n",
       "439                0.066667                    0.675103   \n",
       "440                0.342857                    0.713785   \n",
       "441                0.388000                    0.790799   \n",
       "442                0.200000                    0.808079   \n",
       "443                0.229310                    0.883241   \n",
       "444                0.229310                    0.641615   \n",
       "445                0.388000                    0.773521   \n",
       "446                0.200000                    0.843554   \n",
       "447                0.229310                    0.787257   \n",
       "448                0.229310                    0.808400   \n",
       "449                0.388000                    0.501019   \n",
       "450                0.388000                    0.832357   \n",
       "451                0.200000                    0.809020   \n",
       "452                1.000000                    0.820631   \n",
       "\n",
       "     mean_every_day_trans_amount  cv_mean_every_day_trans_amount  \\\n",
       "0                       0.681788                        0.116594   \n",
       "1                       0.712411                        0.372269   \n",
       "2                       0.764678                        0.320512   \n",
       "3                       0.805407                        0.332435   \n",
       "4                       0.731782                        0.172372   \n",
       "5                       0.694447                        0.271281   \n",
       "6                       0.594147                        0.000000   \n",
       "7                       0.792070                        0.137174   \n",
       "8                       0.791299                        0.201353   \n",
       "9                       0.845970                        0.267214   \n",
       "10                      0.876694                        0.193427   \n",
       "11                      0.870635                        0.215829   \n",
       "12                      0.535109                        0.267675   \n",
       "13                      0.867200                        0.439033   \n",
       "14                      0.756473                        0.182442   \n",
       "15                      0.656154                        0.864225   \n",
       "16                      0.747255                        0.414548   \n",
       "17                      0.832371                        0.320242   \n",
       "18                      0.596954                        0.251150   \n",
       "19                      0.750427                        0.055506   \n",
       "20                      0.819012                        0.305272   \n",
       "21                      1.000000                        0.085584   \n",
       "22                      0.744884                        0.334058   \n",
       "23                      0.851913                        0.123800   \n",
       "24                      0.827077                        0.162704   \n",
       "25                      0.649485                        0.384608   \n",
       "26                      0.722623                        0.592443   \n",
       "27                      0.488975                        0.000000   \n",
       "28                      0.840584                        0.286405   \n",
       "29                      0.924436                        0.195388   \n",
       "..                           ...                             ...   \n",
       "423                     0.809936                        0.368295   \n",
       "424                     0.875133                        0.401496   \n",
       "425                     0.808225                        0.000000   \n",
       "426                     0.585898                        0.660962   \n",
       "427                     0.856396                        0.337651   \n",
       "428                     0.929320                        0.064165   \n",
       "429                     0.721378                        0.313341   \n",
       "430                     0.494345                        0.167604   \n",
       "431                     0.784021                        0.069059   \n",
       "432                     0.880795                        0.132903   \n",
       "433                     0.724362                        0.204883   \n",
       "434                     0.899023                        0.092341   \n",
       "435                     0.863050                        0.043547   \n",
       "436                     0.715596                        0.325975   \n",
       "437                     0.709882                        0.110740   \n",
       "438                     0.794400                        0.642750   \n",
       "439                     0.674527                        0.387475   \n",
       "440                     0.819002                        0.120038   \n",
       "441                     0.903164                        0.238670   \n",
       "442                     0.766093                        0.189625   \n",
       "443                     0.848593                        0.127736   \n",
       "444                     0.707181                        0.218825   \n",
       "445                     0.714732                        0.368544   \n",
       "446                     0.792770                        0.377568   \n",
       "447                     0.742407                        0.220330   \n",
       "448                     0.791970                        0.661120   \n",
       "449                     0.608932                        0.000000   \n",
       "450                     0.765210                        0.554823   \n",
       "451                     0.813148                        0.325633   \n",
       "452                     0.768773                        0.271020   \n",
       "\n",
       "     sum_every_trans_amount  on_sale_rate  sum_before_30_trans_count  \\\n",
       "0                  0.762552      0.989301                   0.189189   \n",
       "1                  0.784500      0.996128                   0.310811   \n",
       "2                  0.711933      0.997082                   0.040541   \n",
       "3                  0.856913      0.998964                   0.797297   \n",
       "4                  0.738287      0.991337                   0.040541   \n",
       "5                  0.772912      0.969885                   0.891892   \n",
       "6                  0.595828      1.000000                   0.000000   \n",
       "7                  0.855037      0.986872                   0.689189   \n",
       "8                  0.792487      0.999581                   0.135135   \n",
       "9                  0.818018      1.000000                   0.108108   \n",
       "10                 0.918974      0.999134                   0.864865   \n",
       "11                 0.910283      0.986701                   0.405405   \n",
       "12                 0.583387      0.996558                   0.243243   \n",
       "13                 0.815644      0.999995                   0.148649   \n",
       "14                 0.818474      0.990046                   0.513514   \n",
       "15                 0.703082      0.956956                   0.229730   \n",
       "16                 0.806658      0.996205                   0.459459   \n",
       "17                 0.869076      0.990873                   0.554054   \n",
       "18                 0.764726      0.999136                   0.040541   \n",
       "19                 0.818207      0.986894                   0.405405   \n",
       "20                 0.835493      0.999942                   0.337838   \n",
       "21                 0.982891      0.999994                   0.337838   \n",
       "22                 0.669342      1.000000                   0.040541   \n",
       "23                 0.885955      0.999602                   0.567568   \n",
       "24                 0.879848      0.999425                   0.797297   \n",
       "25                 0.766073      0.997131                   0.216216   \n",
       "26                 0.839251      0.991960                   0.824324   \n",
       "27                 0.767371      0.999856                   0.000000   \n",
       "28                 0.885828      0.998340                   0.581081   \n",
       "29                 0.960636      0.999351                   0.459459   \n",
       "..                      ...           ...                        ...   \n",
       "423                0.867749      0.988211                   0.486486   \n",
       "424                0.921479      0.998535                   0.878378   \n",
       "425                0.659761      1.000000                   0.000000   \n",
       "426                0.649156      0.949518                   0.378378   \n",
       "427                0.854455      0.999712                   0.256757   \n",
       "428                0.968296      0.991873                   0.486486   \n",
       "429                0.797784      0.989070                   0.756757   \n",
       "430                0.585508      0.892163                   0.175676   \n",
       "431                0.855458      0.994558                   0.756757   \n",
       "432                0.863277      1.000000                   0.256757   \n",
       "433                0.802254      0.984007                   0.702703   \n",
       "434                0.935889      0.999300                   0.418919   \n",
       "435                0.908509      0.988460                   0.513514   \n",
       "436                0.745109      0.998283                   0.351351   \n",
       "437                0.711235      0.996984                   0.054054   \n",
       "438                0.796447      0.989284                   0.324324   \n",
       "439                0.724213      0.992965                   0.324324   \n",
       "440                0.731764      1.000000                   0.054054   \n",
       "441                0.822854      0.999956                   0.067568   \n",
       "442                0.830024      0.999493                   0.797297   \n",
       "443                0.895987      0.998805                   0.810811   \n",
       "444                0.637747      0.998826                   0.027027   \n",
       "445                0.773569      0.978553                   0.418919   \n",
       "446                0.852838      0.990522                   0.986486   \n",
       "447                0.808391      0.998454                   0.810811   \n",
       "448                0.838312      0.978653                   0.702703   \n",
       "449                0.553836      1.000000                   0.000000   \n",
       "450                0.823754      0.987572                   0.756757   \n",
       "451                0.817322      0.954468                   0.175676   \n",
       "452                0.846885      0.992258                   0.472973   \n",
       "\n",
       "     sum_every_trans_count  nearest_trans_day  mean_every_trans_trans_amount  \\\n",
       "0                 0.626667           0.000000                       0.561611   \n",
       "1                 0.773333           0.000000                       0.744346   \n",
       "2                 0.160000           0.000000                       0.794644   \n",
       "3                 0.973333           0.000000                       0.784040   \n",
       "4                 0.226667           0.144928                       0.565122   \n",
       "5                 1.000000           0.000000                       0.610681   \n",
       "6                 0.026667           0.115942                       0.770418   \n",
       "7                 1.000000           0.000000                       0.585341   \n",
       "8                 0.226667           0.014493                       0.902783   \n",
       "9                 0.133333           0.202899                       0.967967   \n",
       "10                0.986667           0.000000                       0.767887   \n",
       "11                1.000000           0.000000                       0.571007   \n",
       "12                0.293333           0.246377                       0.582906   \n",
       "13                0.146667           0.057971                       0.893092   \n",
       "14                0.893333           0.000000                       0.750219   \n",
       "15                0.293333           0.028986                       0.694967   \n",
       "16                0.946667           0.000000                       0.688212   \n",
       "17                0.706667           0.000000                       0.896178   \n",
       "18                0.146667           0.000000                       0.882345   \n",
       "19                1.000000           0.000000                       0.566994   \n",
       "20                0.560000           0.000000                       0.867749   \n",
       "21                0.520000           0.000000                       0.880060   \n",
       "22                0.080000           0.028986                       0.793431   \n",
       "23                0.800000           0.000000                       0.772738   \n",
       "24                1.000000           0.000000                       0.773250   \n",
       "25                0.773333           0.000000                       0.720398   \n",
       "26                0.986667           0.000000                       0.651355   \n",
       "27                0.213333           0.000000                       0.811666   \n",
       "28                1.000000           0.000000                       0.727781   \n",
       "29                1.000000           0.000000                       0.778755   \n",
       "..                     ...                ...                            ...   \n",
       "423               1.000000           0.000000                       0.571048   \n",
       "424               1.000000           0.000000                       0.760763   \n",
       "425               0.013333           0.318841                       0.892236   \n",
       "426               0.493333           0.000000                       0.621394   \n",
       "427               0.440000           0.000000                       0.907041   \n",
       "428               1.000000           0.000000                       0.597660   \n",
       "429               1.000000           0.000000                       0.595777   \n",
       "430               0.466667           0.000000                       0.539435   \n",
       "431               1.000000           0.000000                       0.632609   \n",
       "432               0.280000           0.000000                       0.963196   \n",
       "433               1.000000           0.000000                       0.557894   \n",
       "434               1.000000           0.000000                       0.756640   \n",
       "435               1.000000           0.000000                       0.573589   \n",
       "436               0.440000           0.000000                       0.704433   \n",
       "437               0.253333           0.043478                       0.600914   \n",
       "438               0.320000           0.202899                       0.783439   \n",
       "439               0.560000           0.000000                       0.718502   \n",
       "440               0.053333           0.260870                       0.867743   \n",
       "441               0.146667           0.333333                       0.970059   \n",
       "442               0.960000           0.000000                       0.762305   \n",
       "443               1.000000           0.000000                       0.755180   \n",
       "444               0.066667           0.101449                       0.532932   \n",
       "445               1.000000           0.000000                       0.594988   \n",
       "446               1.000000           0.000000                       0.642273   \n",
       "447               0.906667           0.000000                       0.754321   \n",
       "448               0.960000           0.000000                       0.706901   \n",
       "449               0.013333           0.144928                       0.646947   \n",
       "450               0.986667           0.000000                       0.619384   \n",
       "451               0.293333           0.000000                       0.903587   \n",
       "452               0.920000           0.000000                       0.641304   \n",
       "\n",
       "     mean_good_status  store_num  terminal_num  on_sale_or_not  mean_payer_uid  \n",
       "0            0.935056   0.000000      0.024390        0.105426        0.473908  \n",
       "1            0.818146   0.000000      0.000000        0.116402        0.088984  \n",
       "2            0.449864   0.000000      0.024390        0.146341        0.361470  \n",
       "3            0.932021   0.000000      0.024390        0.126582        0.821560  \n",
       "4            0.904829   0.000000      0.000000        0.156962        0.481249  \n",
       "5            0.891572   0.000000      0.024390        0.114014        0.420009  \n",
       "6            0.328704   0.000000      0.048780        0.000000        0.496544  \n",
       "7            0.984555   0.000000      0.000000        0.172561        0.446453  \n",
       "8            0.688172   0.000000      0.000000        0.064516        0.480303  \n",
       "9            0.309524   0.000000      0.000000        0.000000        0.208855  \n",
       "10           0.904527   0.000000      0.146341        0.105706        0.685529  \n",
       "11           0.968058   0.000000      0.170732        0.081866        0.325189  \n",
       "12           0.899306   0.058824      0.024390        0.125000        0.622408  \n",
       "13           0.484444   0.000000      0.000000        0.026667        0.248172  \n",
       "14           0.783951   0.117647      0.073171        0.051724        0.745378  \n",
       "15           0.826412   0.000000      0.024390        0.040404        0.562654  \n",
       "16           0.893543   0.000000      0.000000        0.134513        0.764757  \n",
       "17           0.651275   0.000000      0.073171        0.116883        0.398468  \n",
       "18           0.283951   0.000000      0.024390        0.039216        0.190521  \n",
       "19           0.943104   0.000000      0.048780        0.128899        0.573588  \n",
       "20           0.822833   0.000000      0.000000        0.020619        0.657442  \n",
       "21           0.858265   0.000000      0.097561        0.007628        0.000000  \n",
       "22           0.271164   0.000000      0.000000        0.000000        0.136932  \n",
       "23           0.959912   0.058824      0.073171        0.018018        0.818574  \n",
       "24           0.918994   0.000000      0.000000        0.075419        0.796086  \n",
       "25           0.891957   0.000000      0.048780        0.106509        0.725929  \n",
       "26           0.933723   0.000000      0.000000        0.137931        0.562636  \n",
       "27           0.337654   0.000000      0.000000        0.016667        0.085388  \n",
       "28           0.973841   0.000000      0.048780        0.011461        0.534772  \n",
       "29           0.924766   0.000000      0.195122        0.112976        0.709432  \n",
       "..                ...        ...           ...             ...             ...  \n",
       "423          0.992512   0.000000      0.048780        0.091013        0.341148  \n",
       "424          0.926623   0.000000      0.048780        0.129102        0.786051  \n",
       "425          0.121212   0.000000      0.000000        0.000000        0.267700  \n",
       "426          0.682660   0.000000      0.000000        0.068182        0.233373  \n",
       "427          0.350560   0.000000      0.048780        0.023256        0.116025  \n",
       "428          0.990923   0.058824      0.097561        0.105905        0.329088  \n",
       "429          0.880013   0.000000      0.097561        0.121321        0.280950  \n",
       "430          0.943470   0.000000      0.024390        0.140351        0.558372  \n",
       "431          0.932616   0.000000      0.000000        0.128921        0.736905  \n",
       "432          0.794326   0.000000      0.000000        0.000000        0.057359  \n",
       "433          0.934973   0.000000      0.000000        0.143611        0.378699  \n",
       "434          0.928423   0.000000      0.243902        0.115562        0.622990  \n",
       "435          0.952519   0.294118      0.195122        0.126900        0.641922  \n",
       "436          0.686226   0.000000      0.000000        0.089888        0.683219  \n",
       "437          0.913623   0.000000      0.048780        0.146853        0.806363  \n",
       "438          0.786657   0.000000      0.024390        0.246575        0.551717  \n",
       "439          0.929337   0.000000      0.000000        0.184211        0.761521  \n",
       "440          0.418210   0.000000      0.024390        0.000000        0.160906  \n",
       "441          0.325581   0.000000      0.024390        0.046512        0.203837  \n",
       "442          0.808522   0.000000      0.024390        0.122563        0.587699  \n",
       "443          0.940084   0.000000      0.097561        0.144381        0.759630  \n",
       "444          0.948854   0.000000      0.000000        0.035714        0.874136  \n",
       "445          0.906602   0.000000      0.024390        0.079227        0.190579  \n",
       "446          0.941422   0.000000      0.073171        0.167361        0.377911  \n",
       "447          0.962147   0.000000      0.048780        0.079295        0.827006  \n",
       "448          0.935918   0.000000      0.024390        0.163424        0.420144  \n",
       "449          0.283951   0.000000      0.024390        0.000000        0.280777  \n",
       "450          0.905278   0.000000      0.073171        0.042290        0.363864  \n",
       "451          0.188811   0.000000      0.073171        0.027972        0.070542  \n",
       "452          0.954892   0.000000      0.097561        0.097060        0.579944  \n",
       "\n",
       "[453 rows x 19 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "train_data = feature_train.drop(['is_30days_overdue'], axis=1)\n",
    "train_target = feature_train['is_30days_overdue']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.25, random_state=1)\n",
    "# clf = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#        colsample_bynode=1, colsample_bytree=0.4, gamma=0,\n",
    "#        learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "#        min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
    "#        nthread=None, objective='binary:logistic', random_state=0,\n",
    "#        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "#        silent=None, subsample=1, verbosity=1)\n",
    "from sklearn.externals import joblib\n",
    "# clf = joblib.load('XGB_changef1_62.m')\n",
    "clf = joblib.load('XGB_gcy_872149.m')\n",
    "# clf = clf.fit(train_data,train_target)\n",
    "print(clf)\n",
    "feature2=feature.copy()\n",
    "feature2.columns=['f11','f10','f0','f8','f5','f2','f7','f4','f12','f6','f13','f17','f9','f3','f14','f1','f18','f16','f15']\n",
    "feature2[['f0','f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18']]\n",
    "feature\n",
    "# y_XGB = clf.predict(feature2[['f0','f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18']])\n",
    "\n",
    "dtest = feature.values\n",
    "y_XGB=clf.predict(dtest)\n",
    "del feature2\n",
    "# f1_score(y_test,y_pridict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:53:16.352053Z",
     "start_time": "2019-12-15T13:53:16.342079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:53:18.591656Z",
     "start_time": "2019-12-15T13:53:18.578096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(y_XGB).count('0')\n",
    "str(y_XGB).count('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:53:30.056372Z",
     "start_time": "2019-12-15T13:53:30.043408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apply_id</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50557025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49510913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50782824</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51967846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51105993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apply_id  y_predict\n",
       "0  50557025        0.0\n",
       "1  49510913        0.0\n",
       "2  50782824        1.0\n",
       "3  51967846        0.0\n",
       "4  51105993        0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_XGB = pd.DataFrame()\n",
    "print(df_XGB)\n",
    "df_XGB.insert(0, 'y_predict', y_XGB)\n",
    "df_XGB.insert(0, 'apply_id', merge_loan['apply_id'].tolist())\n",
    "df_XGB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:53:35.177698Z",
     "start_time": "2019-12-15T13:53:35.169708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apply_id</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50557025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49510913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50782824</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51967846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51105993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52709949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49717847</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51179153</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50083070</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51727931</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apply_id  y_predict\n",
       "0  50557025        0.0\n",
       "1  49510913        0.0\n",
       "2  50782824        1.0\n",
       "3  51967846        0.0\n",
       "4  51105993        0.0\n",
       "5  52709949        0.0\n",
       "6  49717847        1.0\n",
       "7  51179153        0.0\n",
       "8  50083070        1.0\n",
       "9  51727931        1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XGB.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T13:53:47.179296Z",
     "start_time": "2019-12-15T13:53:47.171292Z"
    }
   },
   "outputs": [],
   "source": [
    "df_XGB.to_csv('XGB_predict_changef1_12152153.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面不管"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用train_test_split先试一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用f1非k折的单个决策树还有0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T15:33:51.366786Z",
     "start_time": "2019-11-22T15:33:51.361802Z"
    }
   },
   "outputs": [],
   "source": [
    "y = feature['is_30days_overdue']##标签\n",
    "X = feature.drop(['is_30days_overdue'], axis=1).values##特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T15:49:22.485041Z",
     "start_time": "2019-11-22T15:49:22.467576Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "train_data = feature.drop(['is_30days_overdue'], axis=1)\n",
    "train_target = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.25, random_state=1)\n",
    "clf = DecisionTreeClassifier(max_depth=4,criterion='gini')\n",
    "clf = clf.fit(X_train,y_train)\n",
    "print(clf)\n",
    "y_pridict = clf.predict(X_test)\n",
    "f1_score(y_test,y_pridict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T12:55:56.328753Z",
     "start_time": "2019-11-22T12:55:56.322770Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc=roc_auc_score(y_test,y_pridict)\n",
    "print(\"The AUROC=%f\",roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Positive（TP）意思表示做出Positive的判定，而且判定是正确的。  \n",
    "因此，TP的数值表示正确的Positive判定的个数。  \n",
    "同理，False Positive（TP）数值表示错误的Positive判定的个数。  \n",
    "依此，True Negative（TN）数值表示正确的Negative判定个数。   \n",
    "False Negative（FN）数值表示错误的Negative判定个数。  \n",
    " \n",
    "Precision、Recall、Accuracy、F1 Score（F Score） 四个概念定义：  \n",
    "precision = TP / (TP + FP)   \n",
    "recall = TP / (TP + FN)   \n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)   \n",
    "F1 Score = P*R/2(P+R)，其中P和R分别为 precision 和 recall 如果某个二元分类问题， \n",
    "训练拟合得到了几个模型假设，那么通常我们选择在验证集上，F1 Score 数值最大的那个模型假设。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图中  \n",
    "TN FN  \n",
    "FP TP  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T05:54:30.805791Z",
     "start_time": "2019-11-22T05:54:30.645215Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "# y_true = [2, 1, 0, 1, 2, 0]\n",
    "# y_pred = [2, 0, 0, 1, 2, 1]\n",
    "print(classification_report(y_test,y_pridict))\n",
    "C=confusion_matrix(y_test,y_pridict)\n",
    "print(C, end='\\n\\n')\n",
    "df_cm = pd.DataFrame(C)\n",
    "sns.heatmap(df_cm,annot=True)\n",
    "# y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "# y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "# C2 = confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "# print(C2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练时没有偷懒，没有在较少的label上准确率低，所以直接用交叉验证不用train_test_split看效果更好一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到1被预测成1/1的总数为0.73 比真实准确率0.71高 说明预测的不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T15:49:44.215589Z",
     "start_time": "2019-11-22T15:49:44.180667Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train_data = feature.drop(['is_30days_overdue'], axis=1)\n",
    "train_target = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.25, random_state=1)\n",
    "clf = RandomForestClassifier(max_depth=4,criterion='gini')\n",
    "clf = clf.fit(X_train,y_train)\n",
    "print(clf)\n",
    "y_pridict = clf.predict(X_test)\n",
    "f1_score(y_test,y_pridict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:31:38.580249Z",
     "start_time": "2019-11-22T06:31:38.545341Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "train_data = feature.drop(['is_30days_overdue'], axis=1)\n",
    "train_target = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.25, random_state=1)\n",
    "clf = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
    "            max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "clf = clf.fit(X_train,y_train)\n",
    "print(clf)\n",
    "y_pridict = clf.predict(X_test)\n",
    "f1_score(y_test,y_pridict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T18:13:07.458504Z",
     "start_time": "2019-11-19T18:13:07.451549Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
    "#             max_features=10, max_leaf_nodes=None,\n",
    "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#             min_samples_leaf=5, min_samples_split=10,\n",
    "#             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "#             splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:35:44.301192Z",
     "start_time": "2019-11-22T06:35:44.297202Z"
    }
   },
   "source": [
    "## 交叉验证测试\n",
    " cross_val_score函数直接整合了StratifiedKFold的默认函数~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T16:47:02.893732Z",
     "start_time": "2019-11-22T16:46:32.523248Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "y = feature['is_30days_overdue']##标签\n",
    "X = feature.drop(['is_30days_overdue'], axis=1).values##特征\n",
    "\n",
    "classifiers = [DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
    "            max_features=5, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=14,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'),\n",
    "               XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=0.4, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "       min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
    "       nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1),\n",
    "               AdaBoostClassifier(algorithm='SAMME.R',\n",
    "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=15, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=12,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='random'),\n",
    "          learning_rate=1.0, n_estimators=1, random_state=None),\n",
    "              ]\n",
    "#RandomForestClassifier DesitionTreeClassifier 3个Adaboost XGBoost\n",
    "data = {'DesitionTree':[],'XGBClassifier':[]}\n",
    "result = pd.DataFrame(data)\n",
    "for i in range(15):\n",
    "    list=[]\n",
    "    for clf in classifiers:\n",
    "        score = cross_val_score(clf, X, y, cv=10, scoring='f1')#cv=10：10 折交叉验证法，scoring='accuracy'：返回测试精度\n",
    "        #因为不逾期：逾期约7:5,所以用accuracy至少会有57.2814%正确率，所以用f1进行scoring\n",
    "        #print([np.mean(score)])#显示测试精度平均值\n",
    "        list.append(np.mean(score))\n",
    "    result.loc[i]=list\n",
    "result\n",
    "    #print(f1_score(X,y))\n",
    "#先adaboost再randomforest adaboost结果还好一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree,AdaBoost,RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T15:50:40.133804Z",
     "start_time": "2019-11-22T15:50:38.463054Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y = feature['is_30days_overdue']##标签\n",
    "X = feature.drop(['is_30days_overdue'], axis=1).values##特征\n",
    "\n",
    "classifiers = [DecisionTreeClassifier(max_depth=4,criterion='gini'),AdaBoostClassifier(\n",
    "    random_state=2), RandomForestClassifier(random_state=2),\n",
    "               DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4, max_features=10, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=3, min_samples_split=5, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best'),\n",
    "             DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3, max_features=10, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=3, min_samples_split=12, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best') ]\n",
    "#adaboot和第四个decisiontree明显提升\n",
    "for clf in classifiers:\n",
    "    score = cross_val_score(clf, X, y, cv=10, scoring='f1')#cv=10：10 折交叉验证法，scoring='accuracy'：返回测试精度\n",
    "    #因为不逾期：逾期约7:5,所以用accuracy至少会有57.2814%正确率，所以用f1进行scoring\n",
    "    print([np.mean(score)])#显示测试精度平均值\n",
    "    #print(f1_score(X,y))\n",
    "#先adaboost再randomforest adaboost结果还好一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次（去I1I2I3P1P2P3）是Adaboost降了 DecisionTree升了 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多次Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T17:05:23.871250Z",
     "start_time": "2019-11-22T17:04:37.261692Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "y = feature['is_30days_overdue']##标签\n",
    "X = feature.drop(['is_30days_overdue'], axis=1).values##特征\n",
    "\n",
    "classifiers = [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=7, max_features=15, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=4,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False),\\\n",
    "               DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
    "            max_features=5, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=14,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'),\\\n",
    "        AdaBoostClassifier(algorithm='SAMME.R',\n",
    "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=15, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=12,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='random'),\n",
    "          learning_rate=1.0, n_estimators=1, random_state=None),\\\n",
    "              XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=0.4, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "       min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
    "       nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1)]\n",
    "#RandomForestClassifier DesitionTreeClassifier 3个Adaboost XGBoost\n",
    "data = {'RandomForest':[],'DesitionTree':[],'Adaboost':[],'XGBoost':[]}\n",
    "result = pd.DataFrame(data)\n",
    "for i in range(7):\n",
    "    list=[]\n",
    "    for clf in classifiers:\n",
    "        score = cross_val_score(clf, X, y, cv=10, scoring='f1')#cv=10：10 折交叉验证法，scoring='accuracy'：返回测试精度\n",
    "        #因为不逾期：逾期约7:5,所以用accuracy至少会有57.2814%正确率，所以用f1进行scoring\n",
    "        #print([np.mean(score)])#显示测试精度平均值\n",
    "        list.append(np.mean(score))\n",
    "    result.loc[i]=list\n",
    "result\n",
    "    #print(f1_score(X,y))\n",
    "#先adaboost再randomforest adaboost结果还好一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原来\n",
    "RandomForest\tDesitionTree\tAdaboost1\tAdaboost2\tAdaboost3\tXGBoost\n",
    "0\t0.619503\t0.564263\t0.532618\t0.579869\t0.586894\t0.599188\n",
    "1\t0.630274\t0.564539\t0.590817\t0.581236\t0.589593\t0.599188\n",
    "2\t0.630867\t0.544616\t0.594115\t0.566209\t0.578479\t0.599188\n",
    "3\t0.628147\t0.549137\t0.563573\t0.525717\t0.559777\t0.599188\n",
    "4\t0.617550\t0.572193\t0.573680\t0.567733\t0.561072\t0.599188\n",
    "5\t0.604245\t0.563753\t0.601234\t0.547066\t0.563356\t0.599188\n",
    "6\t0.631666\t0.546882\t0.490676\t0.520370\t0.545420\t0.599188\n",
    "第一次删交易方式\n",
    "可以看到RandomForest收影响不大，DesitionTree疯狂提升但还是不如RF和XGB,Adaboost也有提升\n",
    "\tRandomForest\tDesitionTree\tAdaboost1\tAdaboost2\tAdaboost3\tXGBoost\n",
    "0\t0.619401\t0.601556\t0.571297\t0.556061\t0.567685\t0.617617\n",
    "1\t0.622937\t0.574043\t0.545617\t0.554873\t0.573797\t0.617617\n",
    "2\t0.630850\t0.531901\t0.585603\t0.579894\t0.553374\t0.617617\n",
    "3\t0.616955\t0.582779\t0.582336\t0.550765\t0.565448\t0.617617\n",
    "4\t0.608231\t0.600332\t0.587368\t0.506586\t0.604879\t0.617617\n",
    "5\t0.617595\t0.600352\t0.589645\t0.556198\t0.586399\t0.617617\n",
    "6\t0.639605\t0.581682\t0.545618\t0.583483\t0.602360\t0.617617\n",
    "第二次删I1I2I3P1P2P3\n",
    "可以看到基本维持不变，这可能是因为参数需要再调一波 所以调一下再试\n",
    "RandomForest\tDesitionTree\tAdaboost1\tAdaboost2\tAdaboost3\tXGBoost\n",
    "0\t0.630208\t0.557664\t0.581018\t0.610085\t0.589487\t0.610233\n",
    "1\t0.613704\t0.578765\t0.584903\t0.571300\t0.542334\t0.610233\n",
    "2\t0.634073\t0.576649\t0.541038\t0.574370\t0.610602\t0.610233\n",
    "3\t0.622816\t0.572986\t0.575564\t0.585786\t0.599933\t0.610233\n",
    "4\t0.617320\t0.574186\t0.593813\t0.589618\t0.600303\t0.610233\n",
    "5\t0.619191\t0.567567\t0.574016\t0.595418\t0.591603\t0.610233\n",
    "6\t0.624364\t0.595464\t0.612314\t0.554814\t0.608593\t0.610233\n",
    "最终\n",
    "\n",
    "RandomForest\tDesitionTree\tAdaboost\tXGBoost\n",
    "0\t0.616682\t0.629159\t0.618274\t0.619243\n",
    "1\t0.631258\t0.587805\t0.608033\t0.619243\n",
    "2\t0.619141\t0.564527\t0.583956\t0.619243\n",
    "3\t0.611361\t0.597486\t0.565275\t0.619243\n",
    "4\t0.640254\t0.554826\t0.612308\t0.619243\n",
    "5\t0.628728\t0.626035\t0.546870\t0.619243\n",
    "6\t0.630640\t0.601298\t0.557956\t0.619243\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到RandomForest收影响不大，DesitionTree疯狂提升但还是不如RF和XGB,Adaboost也有提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T15:16:02.497358Z",
     "start_time": "2019-11-22T15:16:02.473736Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'RandomForest':[],'DesitionTree':[],'Adaboost1':[],'Adaboost2':[],'Adaboost3':[],'XGBoost':[]}\n",
    "# 创建一个Series对象\n",
    "result = pd.DataFrame(data)\n",
    "result.iloc[0,1]=1\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T16:00:44.079465Z",
     "start_time": "2019-11-25T16:00:44.050030Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb#调入XGBoost模块\n",
    "from xgboost import plot_importance\n",
    "X = feature.drop(['is_30days_overdue'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=1)\n",
    "feature_name = ['I_1', 'I_2', 'I_3', 'P_1', 'P_2', 'P_3','log_sum_send_amount','lend_period','view_no',\\\n",
    "                    'sum_his_lend_amount', 'mean_his_overdue_times', 'sum_before_30_trans_amount', 'mean_every_day_trans_amount', 'cv_mean_every_day_trans_amount', 'sum_every_trans_amount','on_sale_rate','sum_before_30_trans_count','sum_every_trans_count','nearest_trans_day','mean_every_trans_trans_amount',\\\n",
    "                    'mean_good_status','store_num','terminal_num','on_sale_or_not','mean_payer_uid',\\\n",
    "                    'bankcard_credit_count','bankcard_debit_count','wallet_weixin_count','wallet_alipay_count','alipay_huabei_count']\n",
    "xgbr=xgb.XGBClassifier()#调用XGBRegressor函数‍\n",
    "\n",
    "xgbr.fit(X_train,y_train)#拟合\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_importance(xgbr,ax=ax)\n",
    "\n",
    "plt.show()\n",
    "xgbr_y_predict=xgbr.predict(X_test)#预测\n",
    "f1_score(y_test,xgbr_y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T15:47:59.549348Z",
     "start_time": "2019-11-22T15:47:59.544332Z"
    }
   },
   "source": [
    "可以看到省份也完全没用 也去了 然后绕回去重跑 图记录就不存了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注：由这及特征图可见第三类交易类型特征不好 可以不要！\n",
    "['bankcard_credit_count','bankcard_debit_count','wallet_weixin_count','wallet_alipay_count','alipay_huabei_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T13:20:14.314514Z",
     "start_time": "2019-11-22T13:20:14.309502Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T12:43:09.549082Z",
     "start_time": "2019-11-22T12:43:09.532104Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc=roc_auc_score(y_test,xgbr_y_predict)\n",
    "print(\"The AUROC=%f\",roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T08:06:00.057536Z",
     "start_time": "2019-11-22T08:06:00.023108Z"
    }
   },
   "outputs": [],
   "source": [
    "# y=y.values\n",
    "\n",
    "#设置待选的参数        \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "parameter_grid = {'max_depth': [2,3,4,5,6], 'max_features': [5,8,10,12,14], 'criterion': ['gini', 'entropy'],\n",
    "             'min_samples_split': [5,8,10,12,14], 'min_samples_leaf': [3,4,5,7]}\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "#将不同参数带入\n",
    "gridsearch = GridSearchCV(decision_tree_classifier,\n",
    "                          param_grid = parameter_grid,\n",
    "                          cv = cross_validation)\n",
    "gridsearch.fit(X,y)\n",
    "\n",
    "#得分最高的参数值，并构建最佳的决策树\n",
    "best_param = gridsearch.best_params_\n",
    "\n",
    "# best_param.best_score_\n",
    "# best_decision_tree_classifier = DecisionTreeClassifier(max_depth=best_param['max_depth'],\n",
    "#                                                        max_features=best_param['max_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T12:51:13.599332Z",
     "start_time": "2019-11-18T12:51:13.593348Z"
    }
   },
   "outputs": [],
   "source": [
    "np.isnan(X).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T17:56:41.400918Z",
     "start_time": "2019-11-19T17:56:41.395932Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T17:56:27.836002Z",
     "start_time": "2019-11-19T17:56:27.830019Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T17:56:56.108872Z",
     "start_time": "2019-11-19T17:56:56.103568Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T17:57:41.207621Z",
     "start_time": "2019-11-19T17:57:41.183538Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, (train,test) in enumerate(kf):\n",
    "    print(k,train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T18:02:33.181872Z",
     "start_time": "2019-11-19T18:02:33.161927Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "scores = []\n",
    "kfold = StratifiedKFold(y=y_train, n_folds=10, random_state=1) # n_folds参数设置为10份\n",
    "for train_index, test_index in kfold:\n",
    "    DecisionTreeClassifier(max_depth=4,criterion='gini').fit(X_train[train_index], y_train[train_index])\n",
    "    score = DecisionTreeClassifier(max_depth=4,criterion='gini').score(X_train[test_index], y_train[test_index])\n",
    "    scores.append(score)\n",
    "    print('类别分布: %s, 准确度: %.3f' % (np.bincount(y_train[train_index]), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学习曲线 调参时画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:33:54.914172Z",
     "start_time": "2019-11-22T06:33:48.621434Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义函数 plot_learning_curve 绘制学习曲线。\n",
    "#train_sizes 初始化为 array([ 0.1  ,  0.325,  0.55 ,  0.775,  1\\.   ]),\n",
    "#cv 初始化为 10，以后调用函数时不再输入这两个变量\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=10,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(title) # 设置图的 title\n",
    "    plt.xlabel('Training examples') # 横坐标\n",
    "    plt.ylabel('Score') # 纵坐标\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,\n",
    "                                                            train_sizes=train_sizes, scoring='f1')#画学习曲线 \n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算平均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid() # 设置背景的网格\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1, color='g') # 设置颜色\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                     alpha=0.1, color='r')\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='g',\n",
    "             label='traning score') # 绘制训练精度曲线\n",
    "    for a, b in zip(train_sizes, train_scores_mean):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='testing score') # 绘制测试精度曲线\n",
    "    for a, b in zip(train_sizes, test_scores_mean):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n",
    "g = plot_learning_curve(AdaBoostClassifier(), 'RFC', X, y) # 调用函数 plot_learning_curve 绘制随机森林学习器学习曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:33:59.167119Z",
     "start_time": "2019-11-22T06:33:57.702980Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义函数 plot_learning_curve 绘制学习曲线。\n",
    "#train_sizes 初始化为 array([ 0.1  ,  0.325,  0.55 ,  0.775,  1\\.   ]),\n",
    "#cv 初始化为 10，以后调用函数时不再输入这两个变量\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=10,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(title) # 设置图的 title\n",
    "    plt.xlabel('Training examples') # 横坐标\n",
    "    plt.ylabel('Score') # 纵坐标\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,\n",
    "                                                            train_sizes=train_sizes, scoring='f1')#画学习曲线 \n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算平均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid() # 设置背景的网格\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1, color='g') # 设置颜色\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                     alpha=0.1, color='r')\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='g',\n",
    "             label='traning score') # 绘制训练精度曲线\n",
    "    for a, b in zip(train_sizes, train_scores_mean):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='testing score') # 绘制测试精度曲线\n",
    "    for a, b in zip(train_sizes, test_scores_mean):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "g = plot_learning_curve(RandomForestClassifier(), 'RFC', X, y) # 调用函数 plot_learning_curve 绘制随机森林学习器学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:34:51.430436Z",
     "start_time": "2019-11-22T06:34:51.365584Z"
    }
   },
   "outputs": [],
   "source": [
    "feature.to_csv('feature.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:23:50.043075Z",
     "start_time": "2019-11-17T21:23:50.039086Z"
    }
   },
   "source": [
    "# 决策树 集成学习 随机森林算法 参数调节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Python sklearn 参数调节\n",
    "\n",
    "![image](https://doc.shiyanlou.com/document-uid598017labid4262timestamp1513834446518.png)\n",
    "\n",
    "| 参数              |                                                        | 特点                                           |*\n",
    "| ----------------- | ------------------------------------------------------ | ---------------------------------------------- |\n",
    "| n_estimators      | 基学习器数目（默认值 10）                              | 基本趋势是值越大精度越高 ，直到达到一个上限    |\n",
    "| criterion         | 选择算法 gini 或者 entropy (默认 gini)                 | 视具体情况定                                   |\n",
    "| max_features      | 2.2.3 节中子集的大小，即 k 值（默认 sqrt(n_features)） |                                                |\n",
    "| max_depth         | 决策树深度                                             | 过小基学习器欠拟合，过大基学习器过拟合。粗调节 |\n",
    "| max_leaf_nodes    | 最大叶节点数（默认无限制）                             | 粗调节                                         |\n",
    "| min_samples_split | 分裂时最小样本数，默认 2                               | 细调节, 越小模型越复杂                         |\n",
    "| min_samples_leaf  | 叶节点最小样本数，默认 2                               | 细调节，越小模型越复杂                         |\n",
    "| bootstrap         | 是否采用自助法进行样本抽样（默认使用）                 | 决定基学习器样本是否一致                       |\n",
    "\n",
    "在以上参数中，只有 n_estimators 对精度的影响是单调的。粗调节表示参数选择跨度大，以 10、100 等为单位。细调节参数选择跨度小，以 1、2 等为单位。\n",
    "\n",
    " #####代码实现\n",
    "\n",
    " #####交叉验证法调参\n",
    "\n",
    "首先调节：`n_estimators`，`max_depth`。首先观察特征数目，这决定了 `max_depth` 等参数的范围。然后使用交叉验证法调参。\n",
    "\n",
    "得到最优参数 `n_estimators=60，max_depth=8`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:07:18.069501Z",
     "start_time": "2019-11-18T13:07:18.062520Z"
    }
   },
   "source": [
    "n_estimators:  \n",
    "也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。  \n",
    "一般来说n_estimators太小，容易过拟合，n_estimators太大，又容易欠拟合，一般选择一个适中的数值。默认是100。  \n",
    "在实际调参的过程中，我们常常将n_estimators和下面介绍的参数learning_rate一起考虑。  \n",
    "max_depth  \n",
    "决策树最大深度max_depth, 默认可以不输入，如果不输入的话，决策树在建立子树的时候不会限制子树的深度。  \n",
    "一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下  \n",
    "，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。  \n",
    "参数效果：值越大，决策树越复杂，越容易过拟合。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证法调参\n",
    "首先调节：n_estimators，max_depth。首先观察特征数目，这决定了 max_depth 等参数的范围。然后使用交叉验证法调参。\n",
    "\n",
    "得到最优参数 n_estimators=60，max_depth=8。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DesitionTreeeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:38:12.489861Z",
     "start_time": "2019-11-22T06:38:12.482880Z"
    }
   },
   "outputs": [],
   "source": [
    "DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:41:35.347487Z",
     "start_time": "2019-11-22T06:41:35.051249Z"
    }
   },
   "outputs": [],
   "source": [
    "def para_tune(para, X, y): #\n",
    "    clf = DecisionTreeClassifier(max_depth=para) # n_estimators 设置为 para\n",
    "    score = np.mean(cross_val_score(clf, X, y, scoring='f1'))\n",
    "    return score\n",
    "\n",
    "def accurate_curve(para_range, X, y, title):\n",
    "    score = []\n",
    "    for para in para_range:\n",
    "        score.append(para_tune(para, X, y))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Paramters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid()\n",
    "    plt.plot(para_range, score, 'o-')\n",
    "    for a, b in zip(para_range,  score):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    return plt\n",
    "\n",
    "g = accurate_curve([1,2,3,4,5,6,7], X, y, 'n_estimator tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T06:44:40.006632Z",
     "start_time": "2019-11-22T06:44:39.671490Z"
    }
   },
   "outputs": [],
   "source": [
    "def para_tune(para, X, y): #\n",
    "    clf = DecisionTreeClassifier(criterion=para) # n_estimators 设置为 para\n",
    "    score = np.mean(cross_val_score(clf, X, y, scoring='f1'))\n",
    "    return score\n",
    "\n",
    "def accurate_curve(para_range, X, y, title):\n",
    "    score = []\n",
    "    for para in para_range:\n",
    "        score.append(para_tune(para, X, y))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Paramters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid()\n",
    "    plt.plot(para_range, score, 'o-')\n",
    "    for a, b in zip(para_range,  score):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    return plt\n",
    "\n",
    "g = accurate_curve(['entropy','gini'], X, y, 'criterion tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T18:16:43.681606Z",
     "start_time": "2019-11-19T18:16:41.549308Z"
    }
   },
   "outputs": [],
   "source": [
    "def para_tune(para, X, y): #\n",
    "    clf = RandomForestClassifier(n_estimators=para) # n_estimators 设置为 para\n",
    "    score = np.mean(cross_val_score(clf, X, y, scoring='f1'))\n",
    "    return score\n",
    "\n",
    "def accurate_curve(para_range, X, y, title):\n",
    "    score = []\n",
    "    for para in para_range:\n",
    "        score.append(para_tune(para, X, y))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Paramters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid()\n",
    "    plt.plot(para_range, score, 'o-')\n",
    "    for a, b in zip(para_range,  score):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    return plt\n",
    "\n",
    "g = accurate_curve([2, 10,20,30,40, 50,60, 80], X, y, 'n_estimator tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators 最优50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T18:17:50.334628Z",
     "start_time": "2019-11-19T18:17:48.552484Z"
    }
   },
   "outputs": [],
   "source": [
    "def para_tune(para, X, y):\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=para)\n",
    "    score = np.mean(cross_val_score(clf, X, y, scoring='f1'))\n",
    "    return score\n",
    "\n",
    "def accurate_curve(para_range, X, y, title):\n",
    "    score = []\n",
    "    for para in para_range:\n",
    "        score.append(para_tune(para, X, y))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Paramters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid()\n",
    "    plt.plot(para_range, score, 'o-')\n",
    "    for a, b in zip(para_range,  score):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    return plt\n",
    "\n",
    "g = accurate_curve([2,4,6, 8,10, 12], X, y, 'max_depth tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para_grid = {'max_depth': [6], 'n_estimators': [50], 'max_features': [1, 5, 10], 'criterion': ['gini', 'entropy'],\n",
    "#              'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 5, 10]}#对以上参数进行网格搜索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T18:22:27.839336Z",
     "start_time": "2019-11-19T18:22:25.362811Z"
    }
   },
   "outputs": [],
   "source": [
    "def para_tune(para, X, y):\n",
    "    clf = RandomForestClassifier(n_estimators=50,max_depth=8, max_features=para)\n",
    "    score = np.mean(cross_val_score(clf, X, y, scoring='f1'))\n",
    "    return score\n",
    "\n",
    "def accurate_curve(para_range, X, y, title):\n",
    "    score = []\n",
    "    for para in para_range:\n",
    "        score.append(para_tune(para, X, y))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Paramters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid()\n",
    "    plt.plot(para_range, score, 'o-')\n",
    "    for a, b in zip(para_range,  score):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    return plt\n",
    "\n",
    "g = accurate_curve([1,2,4,6, 8,10, 12], X, y, 'max_features tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_features=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T18:24:33.802628Z",
     "start_time": "2019-11-19T18:24:31.323751Z"
    }
   },
   "outputs": [],
   "source": [
    "def para_tune(para, X, y):\n",
    "    clf = RandomForestClassifier(n_estimators=50,max_depth=8,min_samples_split=para, max_features=10)\n",
    "    score = np.mean(cross_val_score(clf, X, y, scoring='f1'))\n",
    "    return score\n",
    "\n",
    "def accurate_curve(para_range, X, y, title):\n",
    "    score = []\n",
    "    for para in para_range:\n",
    "        score.append(para_tune(para, X, y))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Paramters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid()\n",
    "    plt.plot(para_range, score, 'o-')\n",
    "    for a, b in zip(para_range,  score):  \n",
    "        plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)\n",
    "    return plt\n",
    "\n",
    "g = accurate_curve([2,4,6, 8,10, 12], X, y, 'min_samples_split tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_features=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaboostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn 自动调参函数 GridSearchCV\n",
    "接下来使用这个函数来选择最优的学习器，并绘制上一节实验学到的学习曲线。\n",
    "\n",
    "观察学习曲线，训练精度随样例数目增加而减小，测试精度则增加，过拟合程度降低。并且从学习曲线的变化趋势看，测试精度将随着训练样例的数目的增加而进一步增加。实际上，决策树的深度以及基学习器的数目起主要的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 参数              |                                                        | 特点                                           |*\n",
    "| ----------------- | ------------------------------------------------------ | ---------------------------------------------- |\n",
    "| n_estimators      | 基学习器数目（默认值 10）                              | 基本趋势是值越大精度越高 ，直到达到一个上限    |\n",
    "| criterion         | 选择算法 gini 或者 entropy (默认 gini)                 | 视具体情况定                                   |\n",
    "| max_features      | 2.2.3 节中子集的大小，即 k 值（默认 sqrt(n_features)） |                                                |\n",
    "| max_depth         | 决策树深度                                             | 过小基学习器欠拟合，过大基学习器过拟合。粗调节 |\n",
    "| max_leaf_nodes    | 最大叶节点数（默认无限制）                             | 粗调节                                         |\n",
    "| min_samples_split | 分裂时最小样本数，默认 2                               | 细调节, 越小模型越复杂                         |\n",
    "| min_samples_leaf  | 叶节点最小样本数，默认 2                               | 细调节，越小模型越复杂                         |\n",
    "| bootstrap         | 是否采用自助法进行样本抽样（默认使用）                 | 决定基学习器样本是否一致                       |\n",
    "\n",
    "在以上参数中，只有 n_estimators 对精度的影响是单调的。粗调节表示参数选择跨度大，以 10、100 等为单位。细调节参数选择跨度小，以 1、2 等为单位。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T17:02:18.455333Z",
     "start_time": "2019-11-22T16:54:26.937559Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=10,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title) # 设置图的 title\n",
    "    plt.xlabel('Training examples') # 横坐标\n",
    "    plt.ylabel('Score') # 纵坐标\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,\n",
    "                                                            train_sizes=train_sizes) \n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算平均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid() # 设置背景的网格\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1, color='g') # 设置颜色\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                     alpha=0.1, color='r')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='g',\n",
    "             label='traning score') # 绘制训练精度曲线\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='testing score') # 绘制测试精度曲线\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "para_grid = {'max_depth': [4,5,6,7], 'n_estimators': [50,60,70], 'max_features': [12,15,18], 'criterion': ['gini', 'entropy'],\n",
    "             'min_samples_split': [2,3,4], 'min_samples_leaf': [2,3,4]}#对以上参数进行网格搜索\n",
    "gs = GridSearchCV(clf, param_grid=para_grid, cv=3, scoring='f1')\n",
    "gs.fit(X, y)\n",
    "gs_best = gs.best_estimator_ #选择出最优的学习器\n",
    "print(gs.best_score_) #最优学习器的精度\n",
    "print(gs_best)\n",
    "\n",
    "g = plot_learning_curve(gs_best, 'RFC', X, y)#调用实验2中定义的 plot_learning_curve 绘制学习曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DesitionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  1.criterion  gini  or  entropy\n",
    "  2.splitter  best or random 前者是在所有特征中找最好的切分点 后者是在部分特征中（数据量大的时候）\n",
    "  3.max_features  默认是None（所有），log2，sqrt，N  特征小于50的时候一般使用所有的\n",
    "  #N就是特征属性的个数\n",
    "  4.max_depth  数据少或者特征少的时候可以不管这个值，如果模型样本量多，特征也多的情况下，可以尝试限制下\n",
    "  #防止过拟合\n",
    "  5.min_samples_split  如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。\n",
    "                       如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。\n",
    "  6.min_samples_leaf  这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被\n",
    "                      剪枝，如果样本量不大，不需要管这个值，大些如10W可是尝试下5\n",
    "  7.min_weight_fraction_leaf 这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起\n",
    "                          被剪枝默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，\n",
    "                          或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。\n",
    "  8.max_leaf_nodes 通过限制最大叶子节点数，可以防止过拟合，默认是\"None”，即不限制最大的叶子节点数。\n",
    "                   如果加了限制，算法会建立在最大叶子节点数内最优的决策树。\n",
    "                   如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制\n",
    "                   具体的值可以通过交叉验证得到。\n",
    "  9.class_weight 指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多\n",
    "                 导致训练的决策树过于偏向这些类别。这里可以自己指定各个样本的权重\n",
    "                 如果使用“balanced”，则算法会自己计算权重，样本量少的类别所对应的样本权重会高。\n",
    "  10.min_impurity_split 这个值限制了决策树的增长，如果某节点的不纯度\n",
    "                       (基尼系数，信息增益，均方差，绝对差)小于这个阈值\n",
    "                       则该节点不再生成子节点。即为叶子节点 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 输出学习器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T05:26:40.141032Z",
     "start_time": "2019-11-23T05:26:40.044289Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=10,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title) # 设置图的 title\n",
    "    plt.xlabel('Training examples') # 横坐标\n",
    "    plt.ylabel('Score') # 纵坐标\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,\n",
    "                                                            train_sizes=train_sizes) \n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算平均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid() # 设置背景的网格\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1, color='g') # 设置颜色\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                     alpha=0.1, color='r')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='g',\n",
    "             label='traning score') # 绘制训练精度曲线\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='testing score') # 绘制测试精度曲线\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "para_grid = {'max_depth': [3,4,5], 'max_features': [5,8,10,12,14],'criterion': ['gini', 'entropy'],\n",
    "             'min_samples_split': [5,12,14,16,18,20] ,'min_samples_leaf': [1,2,3,4]}#对以上参数进行网格搜索\n",
    "gs = GridSearchCV(clf, param_grid=para_grid, cv=3, scoring='f1')\n",
    "gs.fit(X, y)\n",
    "gs_best = gs.best_estimator_ #选择出最优的学习器\n",
    "print(gs.best_score_) #最优学习器的精度\n",
    "print(gs_best)\n",
    "g = plot_learning_curve(gs_best, 'RFC', X, y)#调用实验2中定义的 plot_learning_curve 绘制学习曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T04:37:44.553263Z",
     "start_time": "2019-11-19T04:37:43.731477Z"
    }
   },
   "source": [
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=3, min_samples_split=5,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "            \n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=3, min_samples_split=12,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTree的\n",
    "dict_keys(['cv', 'error_score', 'estimator__class_weight', 'estimator__criterion', 'estimator__max_depth', 'estimator__max_features', 'estimator__max_leaf_nodes', 'estimator__min_impurity_decrease', 'estimator__min_impurity_split', 'estimator__min_samples_leaf', 'estimator__min_samples_split', 'estimator__min_weight_fraction_leaf', 'estimator__presort', 'estimator__random_state', 'estimator__splitter', 'estimator', 'fit_params', 'iid', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T04:34:45.596895Z",
     "start_time": "2019-11-19T04:34:45.588915Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.get_params().keys()\n",
    "{'estimator__max_depth': [6], 'estimator__max_features': [1, 5, 10], 'estimator__criterion': ['gini', 'entropy'],\n",
    "             'estimator__min_samples_split': [2, 5, 10], 'estimator__min_samples_leaf': [1, 5, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T16:52:44.261600Z",
     "start_time": "2019-11-22T16:52:37.024988Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def plot_learning_curve(estimator, title, X, y, cv=10,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title) # 设置图的 title\n",
    "    plt.xlabel('Training examples') # 横坐标\n",
    "    plt.ylabel('Score') # 纵坐标\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,\n",
    "                                                            train_sizes=train_sizes) \n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算平均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid() # 设置背景的网格\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1, color='g') # 设置颜色\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                      alpha=0.1, color='r')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='g',\n",
    "             label='traning score') # 绘制训练精度曲线\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='testing score') # 绘制测试精度曲线\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n",
    "# param_grid = {dtc__criterion : [\"gini\", \"entropy\"],\n",
    "#               dtc__splitter :   [\"best\", \"random\"],\n",
    "#               abc__n_estimators: [none, 1, 2]\n",
    "#              }\n",
    "# DTC = DecisionTreeClassifier(random_state = 11, max_features = \"auto\", class_weight = \"auto\",max_depth = None)\n",
    "# ABC = AdaBoostClassifier(base_estimator = DTC)\n",
    "# # run grid search\n",
    "# grid_search_ABC = GridSearchCV(ABC, param_grid=param_grid, scoring = 'roc_auc')\n",
    "\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "# para_grid = {'max_depth': [10], 'n_estimators': [100], 'max_features': [1, 5, 10], 'criterion': ['gini', 'entropy'],\n",
    "#              'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 5, 10]}#对以上参数进行网格搜索\n",
    "para_grid ={\"base_estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "          \"base_estimator__splitter\":   [ \"random\"],\n",
    "          \"n_estimators\": [1],'base_estimator__max_depth': [3,5,7], 'base_estimator__max_features': [12,15,17,19],\n",
    "             'base_estimator__min_samples_split': [7,10,12,15], 'base_estimator__min_samples_leaf': [1,2,3,5,7]}\n",
    "# class_weight=None, criterion='gini', max_depth=None,\n",
    "#             max_features=None, max_leaf_nodes=None,\n",
    "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#             min_samples_leaf=1, min_samples_split=2,\n",
    "#             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "#             splitter='best'),\n",
    "#           learning_rate=1.0, n_estimators=50, random_state=None\n",
    "gs = GridSearchCV(clf, param_grid=para_grid, cv=3, scoring='f1')\n",
    "gs.fit(X, y)\n",
    "gs_best = gs.best_estimator_ #选择出最优的学习器\n",
    "print(gs.best_score_) #最优学习器的精度\n",
    "print(gs_best)\n",
    "\n",
    "g = plot_learning_curve(gs_best, 'RFC', X, y)#调用实验2中定义的 plot_learning_curve 绘制学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T15:09:11.414820Z",
     "start_time": "2019-11-18T15:09:11.408981Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T04:30:25.799850Z",
     "start_time": "2019-11-19T04:30:25.792842Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(), param_grid=para_grid, cv=3, scoring='f1')\n",
    "gs.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf1 = XGBClassifier(max_depth=6,n_estimators=200)#.fit(train_data,train_label)\n",
    "score1 =cross_val_score(clf1,X,y,cv=5,scoring='f1')\n",
    "print(np.mean( score1))\n",
    "\n",
    "clf2 = XGBClassifier(max_depth=4,n_estimators=292)#.fit(train_data,train_label)\n",
    "score2 = cross_val_score(clf2,X,y,cv=5,scoring='f1')\n",
    "print (np.mean(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T12:03:11.757420Z",
     "start_time": "2019-11-22T12:03:11.752431Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T12:03:17.647923Z",
     "start_time": "2019-11-22T12:03:17.641940Z"
    }
   },
   "outputs": [],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB需要调整的参数  \n",
    "\n",
    "max_depth = 5 :  \n",
    "和GBM中的参数相同，这个值为树的最大深度。  \n",
    "这个值也是用来避免过拟合的。max_depth越大，模型会学到更具体更局部的样本。  \n",
    "需要使用CV函数来进行调优。  \n",
    "典型值：3-10  \n",
    "min_child_weight = 1:  \n",
    "决定最小叶子节点样本权重和。  \n",
    "和GBM的 min_child_leaf 参数类似，但不完全一样。XGBoost的这个参数是最小样本权重的和，而GBM参数是最小样本总数。  \n",
    "这个参数用于避免过拟合。当它的值较大时，可以避免模型学习到局部的特殊样本。  \n",
    "但是如果这个值过高，会导致欠拟合。这个参数需要使用CV来调整。  \n",
    "gamma = 0:  \n",
    "在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值。  \n",
    "这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。  \n",
    "subsample：  \n",
    "和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。  \n",
    "减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。  \n",
    "典型值：0.5-1  \n",
    " colsample_bytree：  \n",
    "和GBM里面的max_features参数类似。用来控制每棵随机采样的列数的占比(每一列是一个特征)。  \n",
    "典型值：0.5-  \n",
    "scale_pos_weight = 1:  \n",
    "在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。  \n",
    "以上是我们要进行调参的部分来优化结果（当然有时候n_estimators(迭代次数）也能起到优化作用）  \n",
    "一下过程我们用一步步修改的方法，来查看结果，用for 函数来列举各个调参过程，for函数我就不列举了，直接通过for得出的结果给大家列举最有参数。当然你也可以不用for 来做，可以用sklearn.moedel_selection的  GridSearchCV来快速调参。  \n",
    "\n",
    "我们先从n_estimators  来定  \n",
    "\n",
    "'n_estimators':[100,200,500,1000,1500]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T13:56:16.851603Z",
     "start_time": "2019-11-22T13:56:16.844622Z"
    }
   },
   "source": [
    "n_estimators:[500] (500,600,700,800)\n",
    "\n",
    "min_child_weight:[2] (1,3,5)\n",
    "\n",
    "max_depth:[6] (3-10)\n",
    "\n",
    "gamma:[0]\n",
    "\n",
    "subsample:[1] (0.5-1)\n",
    "\n",
    "colsample_bytree:[0.7] (0.5-1)\n",
    "\n",
    "reg_alpha:[0] (0.01,0.5,1)\n",
    "\n",
    "reg_lambda:[1] （0.01-0.1，1）\n",
    "\n",
    "‍learning_rate:[0.05] (0.01-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T16:44:58.798705Z",
     "start_time": "2019-11-22T16:44:34.314614Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def plot_learning_curve(estimator, title, X, y, cv=10,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title) # 设置图的 title\n",
    "    plt.xlabel('Training examples') # 横坐标\n",
    "    plt.ylabel('Score') # 纵坐标\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,\n",
    "                                                            train_sizes=train_sizes) \n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算平均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid() # 设置背景的网格\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1, color='g') # 设置颜色\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                      alpha=0.1, color='r')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='g',\n",
    "             label='traning score') # 绘制训练精度曲线\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',\n",
    "             label='testing score') # 绘制测试精度曲线\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n",
    "\n",
    "clf = XGBClassifier()\n",
    "# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#        colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
    "#        max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
    "#        n_estimators=100, n_jobs=1, nthread=None,\n",
    "#        objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "#        reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
    "#        subsample=1, verbosity=1)\n",
    "# 'n_estimators':[100,200,500,1000,1500]\n",
    "# n_estimators:[500] (500,600,700,800)\n",
    "# min_child_weight:[2] (1,3,5)\n",
    "# max_depth:[6] (3-10)\n",
    "# gamma:[0]\n",
    "# subsample:[1] (0.5-1)\n",
    "# colsample_bytree:[0.7] (0.5-1)\n",
    "# reg_alpha:[0] (0.01,0.5,1)\n",
    "# reg_lambda:[1] （0.01-0.1，1）\n",
    "# ‍learning_rate:[0.05] (0.01-0.3)\n",
    "# para_grid ={\"n_estimators\":[250,300,350],\"max_depth\":[2,3,4],'colsample_bytree':[0.5,0.6,0.7]}\n",
    "para_grid ={\"n_estimators\":[150,200,250],\"max_depth\":[2,3,4],'colsample_bytree':[0.3,0.4,0.5]}\n",
    "gs = GridSearchCV(clf, param_grid=para_grid, cv=3, scoring='f1')\n",
    "gs.fit(X, y)\n",
    "gs_best = gs.best_estimator_ #选择出最优的学习器\n",
    "print(gs.best_score_) #最优学习器的精度\n",
    "print(gs_best)\n",
    "\n",
    "g = plot_learning_curve(gs_best, 'RFC', X, y)#调用实验2中定义的 plot_learning_curve 绘制学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T14:25:41.597380Z",
     "start_time": "2019-11-22T14:25:41.592397Z"
    }
   },
   "outputs": [],
   "source": [
    "gs_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他方式交叉验证的过程\n",
    "#### cv=None 交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T03:49:06.458048Z",
     "start_time": "2019-11-19T03:49:04.086523Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf1 = GradientBoostingClassifier(max_depth=3,n_estimators=289)#.fit(train_data,train_label) \n",
    "\n",
    "np.mean(cross_val_score(clf1,X,y,cv=5,scoring='f1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解释为什么所有地方都用f1而不用precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用的是 ‘precision’ 和 ’recall‘ 和 ’f1，三者的关系可以用下图来表示\n",
    "\n",
    " ![img](https://img-blog.csdn.net/20180924203640831?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNTkwNjMx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) \n",
    "\n",
    "假设这是一个二元分类的问题\n",
    "\n",
    "准确率（precision）也就是被分类器检测到的数据中 分类正确的部分\n",
    "\n",
    "召回率（recall）就是 正类中被分类正确的部分\n",
    "\n",
    "而F1值就是 准确率和召回率的调和平均数\n",
    "\n",
    "在实际应用中，如果是做搜索类的问题，那就是在保证召回率的情况下提升准确率\n",
    "\n",
    "在做垃圾邮件检测之类的问题，就是要保证准确率的情况下提升召回率\n",
    "\n",
    "具体也就是遇到具体问题看两者的权衡\n",
    "\n",
    "如果两者都要求高，那就需要保证较高的F1 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习中的 precision、recall、accuracy、F1 Score\n",
    "1. 四个概念定义：TP、FP、TN、FN\n",
    "先看四个概念定义： \n",
    "- TP，True Positive \n",
    "- FP，False Positive \n",
    "- TN，True Negative \n",
    "- FN，False Negative\n",
    "\n",
    "如何理解记忆这四个概念定义呢？\n",
    "\n",
    "举个简单的二元分类问题 例子：\n",
    "\n",
    "假设，我们要对某一封邮件做出一个判定，判定这封邮件是垃圾邮件、还是这封邮件不是垃圾邮件？\n",
    "\n",
    "如果判定是垃圾邮件，那就是做出（Positive）的判定； \n",
    "如果判定不是垃圾邮件，那就做出（Negative）的判定。\n",
    "\n",
    "True Positive（TP）意思表示做出Positive的判定，而且判定是正确的。因此，TP的数值表示正确的Positive判定的个数。 \n",
    "同理，False Positive（TP）数值表示错误的Positive判定的个数。 \n",
    "依此，True Negative（TN）数值表示正确的Negative判定个数。 \n",
    "False Negative（FN）数值表示错误的Negative判定个数。\n",
    "\n",
    "2. Precision、Recall、Accuracy、F1 Score（F Score）\n",
    "四个概念定义：\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "F1 Score = P*R/2(P+R)，其中P和R分别为 precision 和 recall\n",
    "如果某个二元分类问题，训练拟合得到了几个模型假设，那么通常我们选择在验证集上，F1 Score 数值最大的那个模型假设。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T03:53:53.955052Z",
     "start_time": "2019-11-19T03:53:45.765041Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf1 = XGBClassifier(max_depth=6,n_estimators=200)#.fit(train_data,train_label)\n",
    "score1 =cross_val_score(clf1,X,y,cv=5,scoring='f1')\n",
    "print(np.mean( score1))\n",
    "\n",
    "clf2 = XGBClassifier(max_depth=4,n_estimators=292)#.fit(train_data,train_label)\n",
    "score2 = cross_val_score(clf2,X,y,cv=5,scoring='f1')\n",
    "print (np.mean(score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T14:50:02.952464Z",
     "start_time": "2019-11-22T14:46:49.271786Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# from sklearn.datasets import make_blobs\n",
    "\n",
    "# X, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.3)\n",
    "\n",
    "clf = SVC(C = 1.0, kernel='linear')\n",
    "clf.fit(X,y)\n",
    "\n",
    "print(clf.score(X,y))\n",
    "plt.figure(figsize=(10,3), dpi=100)\n",
    "plot_hyperplane(clf, X, y, h=0.01, title='Maximiin Margin Hyperplan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T14:45:16.197560Z",
     "start_time": "2019-11-22T14:45:15.457533Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf1 = SVC(kernel='rbf', C=16, gamma=0.18)#.fit(train_data,train_label)\n",
    "score1 = cross_val_score(clf1,X,y,cv=5,scoring='f1')\n",
    "print(np.mean( score1))\n",
    "\n",
    "clf2 = SVC(kernel='rbf', C=94.75, gamma=0.17)#.fit(train_data,train_label)\n",
    "score3 = cross_val_score(clf2,X,y,cv=5,scoring='f1')\n",
    "print (np.mean(score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再次RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T05:38:44.812463Z",
     "start_time": "2019-11-19T05:38:44.643953Z"
    }
   },
   "outputs": [],
   "source": [
    "score2 = cross_val_score(clf,X,y,cv=5,scoring='f1')\n",
    "print (np.mean(score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最终预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T05:48:28.474148Z",
     "start_time": "2019-11-19T05:48:28.457179Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T05:46:00.046087Z",
     "start_time": "2019-11-19T05:45:59.882738Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "#在测试集上测试最优的模型的泛化能力.\n",
    "y_true, y_pred = y, clf.predict(X)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T06:32:18.581384Z",
     "start_time": "2019-11-19T06:32:18.568668Z"
    }
   },
   "outputs": [],
   "source": [
    "#用sklearn的SVC方法来训练数据集，并交叉验证预测精度  \n",
    "from sklearn import metrics  \n",
    "# import matplotlib.pyplot as plt  \n",
    "# import pandas as pd  \n",
    "  \n",
    "# tbl = pd.read_csv(\"./data/bmi.csv\")  \n",
    "# #读取数据  \n",
    "  \n",
    "# label = tbl[\"label\"]  \n",
    "# #读取数据中的标签列  \n",
    "# w = tbl[\"weight\"] / 100   \n",
    "# h = tbl[\"height\"] / 200   \n",
    "# wh = pd.concat([w, h], axis=1)  \n",
    "  \n",
    "# data_train, data_test, label_train, label_test = cross_validation.train_test_split(wh, label)  \n",
    "# #将数据分成两组数据集和测试集  \n",
    "print(clf)\n",
    "# # clf = svm.SVC()  \n",
    "# clf.fit(X,y)  \n",
    "# #训练数据  \n",
    "  \n",
    "predict = clf.predict(X)  \n",
    "#预测数据  \n",
    "print(str(predict.tolist()).count(\"0\"))\n",
    "print(str(predict.tolist()).count(\"1\"))\n",
    "ac_score = metrics.accuracy_score(y, predict)  \n",
    "# #生成测试精度  \n",
    "cl_report = metrics.classification_report(y, predict)  \n",
    "# #生成交叉验证的报告  \n",
    "print(ac_score)  \n",
    "# #显示数据精度  \n",
    "print(cl_report)  \n",
    "# #显示交叉验证数据集报告  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T08:21:15.919190Z",
     "start_time": "2019-11-19T08:21:15.905714Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return (pow(x,3)*np.cos(x/2)+1/2)*np.sqrt(4-pow(x,2))\n",
    "x = np.linspace(-2,2,1000)\n",
    "y = f(x)\n",
    "v = integrate.trapz(y, x)\n",
    "print(v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "380.938px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "559px",
    "left": "1508px",
    "right": "20px",
    "top": "115px",
    "width": "422px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
